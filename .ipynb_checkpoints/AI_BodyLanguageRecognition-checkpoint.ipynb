{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements and first setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.8.6.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\julia\\anaconda3\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: pandas in c:\\users\\julia\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (3.17.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (1.19.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (0.13.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (0.35.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1,circle_radius=1)\n",
    "                                 )\n",
    "        # Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Pose landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        cv2.imshow('Raw webcam Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mediapipe.python.solution_base.SolutionOutputs"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture landmarks and create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.face_landmarks.landmark) + len(results.pose_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the landmarks format\n",
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the csv file\n",
    "with open('coords.csv', mode='w', newline='')as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class name you're trainig\n",
    "class_name = \"Winning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1,circle_radius=1)\n",
    "                                 )\n",
    "        # Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            row = pose_row + face_row\n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        cv2.imshow('Raw webcam Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.377088725566864,\n",
       " 0.4000910520553589,\n",
       " -0.8494803309440613,\n",
       " 0.9998297691345215,\n",
       " 0.41410237550735474,\n",
       " 0.33231469988822937,\n",
       " -0.8451960682868958,\n",
       " 0.9997959733009338,\n",
       " 0.43560677766799927,\n",
       " 0.33191949129104614,\n",
       " -0.8449777364730835,\n",
       " 0.99967360496521,\n",
       " 0.4579119086265564,\n",
       " 0.33251604437828064,\n",
       " -0.8457099199295044,\n",
       " 0.9997970461845398,\n",
       " 0.36254385113716125,\n",
       " 0.3362950086593628,\n",
       " -0.7862470746040344,\n",
       " 0.9997493028640747,\n",
       " 0.34968218207359314,\n",
       " 0.3382493853569031,\n",
       " -0.786911129951477,\n",
       " 0.9995999336242676,\n",
       " 0.33503133058547974,\n",
       " 0.3405217230319977,\n",
       " -0.7875194549560547,\n",
       " 0.9997124671936035,\n",
       " 0.502251923084259,\n",
       " 0.3675001859664917,\n",
       " -0.6513850092887878,\n",
       " 0.9997104406356812,\n",
       " 0.3372694253921509,\n",
       " 0.3799232840538025,\n",
       " -0.3661612868309021,\n",
       " 0.9993034601211548,\n",
       " 0.42581748962402344,\n",
       " 0.4679778516292572,\n",
       " -0.7631285786628723,\n",
       " 0.9999024271965027,\n",
       " 0.36058521270751953,\n",
       " 0.473202645778656,\n",
       " -0.6838585138320923,\n",
       " 0.9998311400413513,\n",
       " 0.6713072657585144,\n",
       " 0.733101487159729,\n",
       " -0.5217053294181824,\n",
       " 0.9991188049316406,\n",
       " 0.24889032542705536,\n",
       " 0.7474600672721863,\n",
       " -0.06367405503988266,\n",
       " 0.9987872242927551,\n",
       " 0.8020962476730347,\n",
       " 1.027490496635437,\n",
       " -0.48699188232421875,\n",
       " 0.4183289706707001,\n",
       " 0.20740430057048798,\n",
       " 1.066985845565796,\n",
       " 0.2506295442581177,\n",
       " 0.2536592483520508,\n",
       " 0.8385289907455444,\n",
       " 1.4867194890975952,\n",
       " -0.49312329292297363,\n",
       " 0.1797296106815338,\n",
       " 0.13998892903327942,\n",
       " 1.4693446159362793,\n",
       " 0.07660628110170364,\n",
       " 0.1476423144340515,\n",
       " 0.8792412877082825,\n",
       " 1.5953088998794556,\n",
       " -0.5234755277633667,\n",
       " 0.17703354358673096,\n",
       " 0.10075888782739639,\n",
       " 1.5727038383483887,\n",
       " 0.01896084100008011,\n",
       " 0.14958617091178894,\n",
       " 0.8229048848152161,\n",
       " 1.6037604808807373,\n",
       " -0.6034413576126099,\n",
       " 0.21833248436450958,\n",
       " 0.13981394469738007,\n",
       " 1.5915368795394897,\n",
       " -0.07282476127147675,\n",
       " 0.17596237361431122,\n",
       " 0.7991901636123657,\n",
       " 1.5633736848831177,\n",
       " -0.5176814794540405,\n",
       " 0.22168609499931335,\n",
       " 0.16615892946720123,\n",
       " 1.5524417161941528,\n",
       " 0.018137075006961823,\n",
       " 0.17160168290138245,\n",
       " 0.5892689228057861,\n",
       " 1.5379034280776978,\n",
       " -0.2018115073442459,\n",
       " 0.0005751312710344791,\n",
       " 0.31032106280326843,\n",
       " 1.530701756477356,\n",
       " 0.20471787452697754,\n",
       " 0.0005608412902802229,\n",
       " 0.5761967897415161,\n",
       " 2.1763014793395996,\n",
       " -0.12115802615880966,\n",
       " 0.0008316783932968974,\n",
       " 0.3027549982070923,\n",
       " 2.1617367267608643,\n",
       " 0.30047810077667236,\n",
       " 0.001176708028651774,\n",
       " 0.5770574808120728,\n",
       " 2.7449629306793213,\n",
       " 0.6202991604804993,\n",
       " 0.0001384033093927428,\n",
       " 0.30140531063079834,\n",
       " 2.7252964973449707,\n",
       " 0.6890294551849365,\n",
       " 0.00023199936549644917,\n",
       " 0.5929639339447021,\n",
       " 2.8378682136535645,\n",
       " 0.6828615665435791,\n",
       " 9.84002836048603e-05,\n",
       " 0.30760207772254944,\n",
       " 2.8165948390960693,\n",
       " 0.717450737953186,\n",
       " 0.0004157750227022916,\n",
       " 0.5133026242256165,\n",
       " 2.9234416484832764,\n",
       " 0.3385029733181,\n",
       " 0.0001673881633905694,\n",
       " 0.301897794008255,\n",
       " 2.906087636947632,\n",
       " 0.28380146622657776,\n",
       " 0.0004233978979755193,\n",
       " 0.36810949444770813,\n",
       " 0.4806097149848938,\n",
       " -0.016003787517547607,\n",
       " 0.0,\n",
       " 0.3577258586883545,\n",
       " 0.4415118992328644,\n",
       " -0.04302625730633736,\n",
       " 0.0,\n",
       " 0.3654845952987671,\n",
       " 0.45167076587677,\n",
       " -0.019900323823094368,\n",
       " 0.0,\n",
       " 0.3527950942516327,\n",
       " 0.3977629244327545,\n",
       " -0.034507330507040024,\n",
       " 0.0,\n",
       " 0.3562472462654114,\n",
       " 0.4288254380226135,\n",
       " -0.047264061868190765,\n",
       " 0.0,\n",
       " 0.357198566198349,\n",
       " 0.4109709858894348,\n",
       " -0.04597053304314613,\n",
       " 0.0,\n",
       " 0.3622037470340729,\n",
       " 0.36623620986938477,\n",
       " -0.030159184709191322,\n",
       " 0.0,\n",
       " 0.3173014521598816,\n",
       " 0.3634161353111267,\n",
       " 0.02283594012260437,\n",
       " 0.0,\n",
       " 0.3623816967010498,\n",
       " 0.33794713020324707,\n",
       " -0.02908872626721859,\n",
       " 0.0,\n",
       " 0.3608987331390381,\n",
       " 0.3214510381221771,\n",
       " -0.03325899690389633,\n",
       " 0.0,\n",
       " 0.35979098081588745,\n",
       " 0.2531140446662903,\n",
       " -0.033133942633867264,\n",
       " 0.0,\n",
       " 0.3690284490585327,\n",
       " 0.48654988408088684,\n",
       " -0.013976243324577808,\n",
       " 0.0,\n",
       " 0.37049323320388794,\n",
       " 0.49027329683303833,\n",
       " -0.01055131759494543,\n",
       " 0.0,\n",
       " 0.37214869260787964,\n",
       " 0.49105578660964966,\n",
       " -0.0063714440912008286,\n",
       " 0.0,\n",
       " 0.37239617109298706,\n",
       " 0.4906752407550812,\n",
       " -0.004660116508603096,\n",
       " 0.0,\n",
       " 0.37222573161125183,\n",
       " 0.4957438111305237,\n",
       " -0.005496366415172815,\n",
       " 0.0,\n",
       " 0.3725851774215698,\n",
       " 0.5020949840545654,\n",
       " -0.006710882764309645,\n",
       " 0.0,\n",
       " 0.3737502098083496,\n",
       " 0.5091457962989807,\n",
       " -0.004975052550435066,\n",
       " 0.0,\n",
       " 0.3772584795951843,\n",
       " 0.5209827423095703,\n",
       " 0.003727078903466463,\n",
       " 0.0,\n",
       " 0.3600707948207855,\n",
       " 0.4473347067832947,\n",
       " -0.03817782178521156,\n",
       " 0.0,\n",
       " 0.3549072742462158,\n",
       " 0.4451836347579956,\n",
       " -0.02436693385243416,\n",
       " 0.0,\n",
       " 0.2989969253540039,\n",
       " 0.3144354224205017,\n",
       " 0.06441771984100342,\n",
       " 0.0,\n",
       " 0.34020137786865234,\n",
       " 0.37079954147338867,\n",
       " 0.008721713908016682,\n",
       " 0.0,\n",
       " 0.3328102231025696,\n",
       " 0.3726680278778076,\n",
       " 0.011923760175704956,\n",
       " 0.0,\n",
       " 0.3254525363445282,\n",
       " 0.3730584979057312,\n",
       " 0.016507405787706375,\n",
       " 0.0,\n",
       " 0.3159555196762085,\n",
       " 0.36738845705986023,\n",
       " 0.025955110788345337,\n",
       " 0.0,\n",
       " 0.34549784660339355,\n",
       " 0.3672277629375458,\n",
       " 0.006264307536184788,\n",
       " 0.0,\n",
       " 0.3248451352119446,\n",
       " 0.3479226231575012,\n",
       " 0.004657328128814697,\n",
       " 0.0,\n",
       " 0.33286845684051514,\n",
       " 0.34742629528045654,\n",
       " 0.0013220603577792645,\n",
       " 0.0,\n",
       " 0.3180960416793823,\n",
       " 0.34971684217453003,\n",
       " 0.01033096481114626,\n",
       " 0.0,\n",
       " 0.31445926427841187,\n",
       " 0.35292184352874756,\n",
       " 0.015845105051994324,\n",
       " 0.0,\n",
       " 0.3118962347507477,\n",
       " 0.37487927079200745,\n",
       " 0.03242045268416405,\n",
       " 0.0,\n",
       " 0.3530604839324951,\n",
       " 0.5400038957595825,\n",
       " 0.026287885382771492,\n",
       " 0.0,\n",
       " 0.31474390625953674,\n",
       " 0.36137521266937256,\n",
       " 0.025902723893523216,\n",
       " 0.0,\n",
       " 0.3020181357860565,\n",
       " 0.36643609404563904,\n",
       " 0.07699679583311081,\n",
       " 0.0,\n",
       " 0.30566883087158203,\n",
       " 0.3668820261955261,\n",
       " 0.0422278456389904,\n",
       " 0.0,\n",
       " 0.3322151303291321,\n",
       " 0.42435023188591003,\n",
       " 0.008671094663441181,\n",
       " 0.0,\n",
       " 0.35827723145484924,\n",
       " 0.478383332490921,\n",
       " -0.011937389150261879,\n",
       " 0.0,\n",
       " 0.3625740706920624,\n",
       " 0.4897533059120178,\n",
       " -0.006370261777192354,\n",
       " 0.0,\n",
       " 0.35023829340934753,\n",
       " 0.48012658953666687,\n",
       " -0.002811438636854291,\n",
       " 0.0,\n",
       " 0.3465522825717926,\n",
       " 0.483263224363327,\n",
       " 0.006687765475362539,\n",
       " 0.0,\n",
       " 0.3565467894077301,\n",
       " 0.4889279007911682,\n",
       " 9.683264215709642e-05,\n",
       " 0.0,\n",
       " 0.3524835705757141,\n",
       " 0.48880699276924133,\n",
       " 0.008159708231687546,\n",
       " 0.0,\n",
       " 0.34328794479370117,\n",
       " 0.498458594083786,\n",
       " 0.025395141914486885,\n",
       " 0.0,\n",
       " 0.35113322734832764,\n",
       " 0.44114986062049866,\n",
       " -0.04066867381334305,\n",
       " 0.0,\n",
       " 0.34897834062576294,\n",
       " 0.429081529378891,\n",
       " -0.04422885552048683,\n",
       " 0.0,\n",
       " 0.30245688557624817,\n",
       " 0.3415603041648865,\n",
       " 0.019072474911808968,\n",
       " 0.0,\n",
       " 0.34551888704299927,\n",
       " 0.39229345321655273,\n",
       " -0.0017809986602514982,\n",
       " 0.0,\n",
       " 0.3385145664215088,\n",
       " 0.43348097801208496,\n",
       " -0.013991435058414936,\n",
       " 0.0,\n",
       " 0.33916956186294556,\n",
       " 0.4261176586151123,\n",
       " -0.011755488812923431,\n",
       " 0.0,\n",
       " 0.3139250576496124,\n",
       " 0.422078937292099,\n",
       " 0.027184218168258667,\n",
       " 0.0,\n",
       " 0.35036683082580566,\n",
       " 0.41234254837036133,\n",
       " -0.04070301726460457,\n",
       " 0.0,\n",
       " 0.31446167826652527,\n",
       " 0.33101433515548706,\n",
       " -0.004857624880969524,\n",
       " 0.0,\n",
       " 0.30618321895599365,\n",
       " 0.3345377743244171,\n",
       " 0.006375654600560665,\n",
       " 0.0,\n",
       " 0.29941999912261963,\n",
       " 0.29415735602378845,\n",
       " 0.04169538989663124,\n",
       " 0.0,\n",
       " 0.34681040048599243,\n",
       " 0.33767834305763245,\n",
       " -0.021826598793268204,\n",
       " 0.0,\n",
       " 0.34050479531288147,\n",
       " 0.3489534854888916,\n",
       " 0.0020636001136153936,\n",
       " 0.0,\n",
       " 0.3361106514930725,\n",
       " 0.4877552390098572,\n",
       " 0.02849358320236206,\n",
       " 0.0,\n",
       " 0.32515430450439453,\n",
       " 0.47383126616477966,\n",
       " 0.11497942358255386,\n",
       " 0.0,\n",
       " 0.3449195623397827,\n",
       " 0.44025054574012756,\n",
       " -0.011987011879682541,\n",
       " 0.0,\n",
       " 0.3518069088459015,\n",
       " 0.44511717557907104,\n",
       " -0.015314414165914059,\n",
       " 0.0,\n",
       " 0.3437742590904236,\n",
       " 0.48783057928085327,\n",
       " 0.025813614949584007,\n",
       " 0.0,\n",
       " 0.3472643196582794,\n",
       " 0.4874311089515686,\n",
       " 0.021954603493213654,\n",
       " 0.0,\n",
       " 0.30258750915527344,\n",
       " 0.32582947611808777,\n",
       " 0.010742733255028725,\n",
       " 0.0,\n",
       " 0.3402244448661804,\n",
       " 0.43784305453300476,\n",
       " -0.008811001665890217,\n",
       " 0.0,\n",
       " 0.32759132981300354,\n",
       " 0.3312068581581116,\n",
       " -0.014349140226840973,\n",
       " 0.0,\n",
       " 0.32474061846733093,\n",
       " 0.32060229778289795,\n",
       " -0.017126288264989853,\n",
       " 0.0,\n",
       " 0.31756269931793213,\n",
       " 0.26476842164993286,\n",
       " -0.005781199317425489,\n",
       " 0.0,\n",
       " 0.30078190565109253,\n",
       " 0.30923014879226685,\n",
       " 0.02408747561275959,\n",
       " 0.0,\n",
       " 0.32132256031036377,\n",
       " 0.2912153899669647,\n",
       " -0.011919084005057812,\n",
       " 0.0,\n",
       " 0.29945212602615356,\n",
       " 0.33523425459861755,\n",
       " 0.026951681822538376,\n",
       " 0.0,\n",
       " 0.29887646436691284,\n",
       " 0.32542550563812256,\n",
       " 0.04446517676115036,\n",
       " 0.0,\n",
       " 0.36009982228279114,\n",
       " 0.4853372573852539,\n",
       " -0.009964840486645699,\n",
       " 0.0,\n",
       " 0.35355979204177856,\n",
       " 0.4858185052871704,\n",
       " -0.0015905204927548766,\n",
       " 0.0,\n",
       " 0.3494008481502533,\n",
       " 0.4863869249820709,\n",
       " 0.0067540486343204975,\n",
       " 0.0,\n",
       " 0.3474961817264557,\n",
       " 0.4424240291118622,\n",
       " -0.011302565224468708,\n",
       " 0.0,\n",
       " 0.3454829454421997,\n",
       " 0.48773789405822754,\n",
       " 0.023612508550286293,\n",
       " 0.0,\n",
       " 0.34842732548713684,\n",
       " 0.4898654818534851,\n",
       " 0.017006170004606247,\n",
       " 0.0,\n",
       " 0.3483844995498657,\n",
       " 0.4869285225868225,\n",
       " 0.021314332261681557,\n",
       " 0.0,\n",
       " 0.34594395756721497,\n",
       " 0.4382639229297638,\n",
       " -0.02492406778037548,\n",
       " 0.0,\n",
       " 0.35493674874305725,\n",
       " 0.4877883791923523,\n",
       " 0.0093553951010108,\n",
       " 0.0,\n",
       " 0.3594101667404175,\n",
       " 0.48893558979034424,\n",
       " 0.0033636116422712803,\n",
       " 0.0,\n",
       " 0.3652321398258209,\n",
       " 0.49040406942367554,\n",
       " -0.0022637080401182175,\n",
       " 0.0,\n",
       " 0.36736583709716797,\n",
       " 0.5200955867767334,\n",
       " 0.007154288236051798,\n",
       " 0.0,\n",
       " 0.3645530343055725,\n",
       " 0.5078796148300171,\n",
       " -0.0013968492858111858,\n",
       " 0.0,\n",
       " 0.3638244569301605,\n",
       " 0.5006673336029053,\n",
       " -0.0027384995482861996,\n",
       " 0.0,\n",
       " 0.36406585574150085,\n",
       " 0.494442880153656,\n",
       " -0.0013866217341274023,\n",
       " 0.0,\n",
       " 0.36492595076560974,\n",
       " 0.4902271628379822,\n",
       " -0.0006514237611554563,\n",
       " 0.0,\n",
       " 0.35445699095726013,\n",
       " 0.4884082078933716,\n",
       " 0.010346590541303158,\n",
       " 0.0,\n",
       " 0.353222131729126,\n",
       " 0.4898219108581543,\n",
       " 0.009280306287109852,\n",
       " 0.0,\n",
       " 0.3517581820487976,\n",
       " 0.4929848909378052,\n",
       " 0.008920764550566673,\n",
       " 0.0,\n",
       " 0.35087448358535767,\n",
       " 0.4970362186431885,\n",
       " 0.011386804282665253,\n",
       " 0.0,\n",
       " 0.3389189839363098,\n",
       " 0.4694673418998718,\n",
       " 0.00908644124865532,\n",
       " 0.0,\n",
       " 0.3154381811618805,\n",
       " 0.41558441519737244,\n",
       " 0.12106722593307495,\n",
       " 0.0,\n",
       " 0.36269116401672363,\n",
       " 0.4490114152431488,\n",
       " -0.02647249959409237,\n",
       " 0.0,\n",
       " 0.3518727123737335,\n",
       " 0.48794201016426086,\n",
       " 0.01676327735185623,\n",
       " 0.0,\n",
       " 0.3500996232032776,\n",
       " 0.48842430114746094,\n",
       " 0.016265416517853737,\n",
       " 0.0,\n",
       " 0.3551349341869354,\n",
       " 0.45117470622062683,\n",
       " -0.014766408130526543,\n",
       " 0.0,\n",
       " 0.34460899233818054,\n",
       " 0.44491201639175415,\n",
       " -0.003328978084027767,\n",
       " 0.0,\n",
       " 0.35342225432395935,\n",
       " 0.44839775562286377,\n",
       " -0.015394837595522404,\n",
       " 0.0,\n",
       " 0.3393581807613373,\n",
       " 0.39920610189437866,\n",
       " 0.00513292383402586,\n",
       " 0.0,\n",
       " 0.32836365699768066,\n",
       " 0.408092737197876,\n",
       " 0.012418197467923164,\n",
       " 0.0,\n",
       " 0.3396916389465332,\n",
       " 0.430768221616745,\n",
       " -0.0060761007480323315,\n",
       " 0.0,\n",
       " 0.3047567903995514,\n",
       " 0.27727097272872925,\n",
       " 0.017281608656048775,\n",
       " 0.0,\n",
       " 0.30775561928749084,\n",
       " 0.29733210802078247,\n",
       " 0.0057996767573058605,\n",
       " 0.0,\n",
       " 0.31114649772644043,\n",
       " 0.32034820318222046,\n",
       " -0.00357989314943552,\n",
       " 0.0,\n",
       " 0.3498818278312683,\n",
       " 0.5066052675247192,\n",
       " 0.019722413271665573,\n",
       " 0.0,\n",
       " 0.3420536518096924,\n",
       " 0.3218401074409485,\n",
       " -0.02674798294901848,\n",
       " 0.0,\n",
       " 0.3382367789745331,\n",
       " 0.28829601407051086,\n",
       " -0.024803347885608673,\n",
       " 0.0,\n",
       " 0.3352055549621582,\n",
       " 0.25734150409698486,\n",
       " -0.02276124432682991,\n",
       " 0.0,\n",
       " 0.3193356990814209,\n",
       " 0.37136954069137573,\n",
       " 0.021900366991758347,\n",
       " 0.0,\n",
       " 0.3064696788787842,\n",
       " 0.38302990794181824,\n",
       " 0.04097555950284004,\n",
       " 0.0,\n",
       " 0.3483406603336334,\n",
       " 0.36402755975723267,\n",
       " 0.005782953463494778,\n",
       " 0.0,\n",
       " 0.3084033131599426,\n",
       " 0.35476428270339966,\n",
       " 0.025792744010686874,\n",
       " 0.0,\n",
       " 0.3493594825267792,\n",
       " 0.3847973346710205,\n",
       " -0.00771418446674943,\n",
       " 0.0,\n",
       " 0.3407815992832184,\n",
       " 0.43062108755111694,\n",
       " -0.024422701448202133,\n",
       " 0.0,\n",
       " 0.3023390471935272,\n",
       " 0.390634685754776,\n",
       " 0.05497623607516289,\n",
       " 0.0,\n",
       " 0.3096914291381836,\n",
       " 0.39190569519996643,\n",
       " 0.03346361219882965,\n",
       " 0.0,\n",
       " 0.3173486590385437,\n",
       " 0.39654847979545593,\n",
       " 0.02289164438843727,\n",
       " 0.0,\n",
       " 0.3305511772632599,\n",
       " 0.3940521776676178,\n",
       " 0.01390058547258377,\n",
       " 0.0,\n",
       " 0.3402356803417206,\n",
       " 0.3881601393222809,\n",
       " 0.007778932340443134,\n",
       " 0.0,\n",
       " 0.34668850898742676,\n",
       " 0.38225868344306946,\n",
       " 0.0018461061408743262,\n",
       " 0.0,\n",
       " 0.3555542826652527,\n",
       " 0.3696836531162262,\n",
       " -0.023645536974072456,\n",
       " 0.0,\n",
       " 0.30368873476982117,\n",
       " 0.4157336354255676,\n",
       " 0.05652344971895218,\n",
       " 0.0,\n",
       " 0.3036663830280304,\n",
       " 0.3527870178222656,\n",
       " 0.03134734928607941,\n",
       " 0.0,\n",
       " 0.3560429513454437,\n",
       " 0.4468224346637726,\n",
       " -0.03630424663424492,\n",
       " 0.0,\n",
       " 0.34491047263145447,\n",
       " 0.40544039011001587,\n",
       " -0.003506772220134735,\n",
       " 0.0,\n",
       " 0.3074467182159424,\n",
       " 0.3629026710987091,\n",
       " 0.10629350692033768,\n",
       " 0.0,\n",
       " 0.35099080204963684,\n",
       " 0.3761124312877655,\n",
       " -0.0025327331386506557,\n",
       " 0.0,\n",
       " 0.34122344851493835,\n",
       " 0.43050581216812134,\n",
       " 0.00263331551104784,\n",
       " 0.0,\n",
       " 0.31319162249565125,\n",
       " 0.36156803369522095,\n",
       " 0.028476353734731674,\n",
       " 0.0,\n",
       " 0.341709703207016,\n",
       " 0.42167240381240845,\n",
       " -0.02205348014831543,\n",
       " 0.0,\n",
       " 0.3195084035396576,\n",
       " 0.44395413994789124,\n",
       " 0.12053725123405457,\n",
       " 0.0,\n",
       " 0.34779608249664307,\n",
       " 0.3599810302257538,\n",
       " 0.007370066829025745,\n",
       " 0.0,\n",
       " 0.3455657958984375,\n",
       " 0.41596272587776184,\n",
       " -0.03291017934679985,\n",
       " 0.0,\n",
       " 0.32924437522888184,\n",
       " 0.507011353969574,\n",
       " 0.06687851250171661,\n",
       " 0.0,\n",
       " 0.33638691902160645,\n",
       " 0.5186811089515686,\n",
       " 0.08426967263221741,\n",
       " 0.0,\n",
       " 0.30609291791915894,\n",
       " 0.41675010323524475,\n",
       " 0.0897127091884613,\n",
       " 0.0,\n",
       " 0.3220902383327484,\n",
       " 0.4895647168159485,\n",
       " 0.07912351936101913,\n",
       " 0.0,\n",
       " 0.3002128303050995,\n",
       " 0.34396857023239136,\n",
       " 0.06303483247756958,\n",
       " 0.0,\n",
       " 0.3537115156650543,\n",
       " 0.5526743531227112,\n",
       " 0.033948272466659546,\n",
       " 0.0,\n",
       " 0.35923486948013306,\n",
       " 0.4485533833503723,\n",
       " -0.025055477395653725,\n",
       " 0.0,\n",
       " 0.34017837047576904,\n",
       " 0.4141499400138855,\n",
       " 0.0028088202234357595,\n",
       " 0.0,\n",
       " 0.30263835191726685,\n",
       " 0.36839500069618225,\n",
       " 0.053447507321834564,\n",
       " 0.0,\n",
       " 0.3249179720878601,\n",
       " 0.3658846914768219,\n",
       " 0.01593617908656597,\n",
       " 0.0,\n",
       " 0.3319666385650635,\n",
       " 0.3659442663192749,\n",
       " 0.01197886187583208,\n",
       " 0.0,\n",
       " 0.34691306948661804,\n",
       " 0.49212634563446045,\n",
       " 0.019544176757335663,\n",
       " 0.0,\n",
       " 0.30753788352012634,\n",
       " 0.4395797848701477,\n",
       " 0.06238522753119469,\n",
       " 0.0,\n",
       " 0.369235098361969,\n",
       " 0.570769727230072,\n",
       " 0.03410274162888527,\n",
       " 0.0,\n",
       " 0.3509237766265869,\n",
       " 0.5502945780754089,\n",
       " 0.056880705058574677,\n",
       " 0.0,\n",
       " 0.34422898292541504,\n",
       " 0.5368543863296509,\n",
       " 0.06906910240650177,\n",
       " 0.0,\n",
       " 0.3599452078342438,\n",
       " 0.28630492091178894,\n",
       " -0.033629655838012695,\n",
       " 0.0,\n",
       " 0.3854958415031433,\n",
       " 0.5742552876472473,\n",
       " 0.02663484588265419,\n",
       " 0.0,\n",
       " 0.3383362293243408,\n",
       " 0.3643121123313904,\n",
       " 0.009103848598897457,\n",
       " 0.0,\n",
       " 0.34365612268447876,\n",
       " 0.3615621328353882,\n",
       " 0.007886763662099838,\n",
       " 0.0,\n",
       " 0.3466024696826935,\n",
       " 0.3604016900062561,\n",
       " 0.008124551735818386,\n",
       " 0.0,\n",
       " 0.30085623264312744,\n",
       " 0.34945568442344666,\n",
       " 0.04125070199370384,\n",
       " 0.0,\n",
       " 0.3414829671382904,\n",
       " 0.3561025857925415,\n",
       " 0.005666229408234358,\n",
       " 0.0,\n",
       " 0.3350095748901367,\n",
       " 0.35575875639915466,\n",
       " 0.005488711874932051,\n",
       " 0.0,\n",
       " 0.3281821012496948,\n",
       " 0.3562542796134949,\n",
       " 0.008159367367625237,\n",
       " 0.0,\n",
       " 0.3216923177242279,\n",
       " 0.3579118847846985,\n",
       " 0.012696572579443455,\n",
       " 0.0,\n",
       " 0.31797167658805847,\n",
       " 0.35980573296546936,\n",
       " 0.01709696464240551,\n",
       " 0.0,\n",
       " 0.30167442560195923,\n",
       " 0.33589914441108704,\n",
       " 0.08721458911895752,\n",
       " 0.0,\n",
       " 0.3203759789466858,\n",
       " 0.3647913336753845,\n",
       " 0.019869621843099594,\n",
       " 0.0,\n",
       " 0.36687755584716797,\n",
       " 0.4606693983078003,\n",
       " -0.016814682632684708,\n",
       " 0.0,\n",
       " 0.3433516025543213,\n",
       " 0.46297022700309753,\n",
       " 0.0006273767212405801,\n",
       " 0.0,\n",
       " 0.343694806098938,\n",
       " 0.438957542181015,\n",
       " -0.016142217442393303,\n",
       " 0.0,\n",
       " 0.35594984889030457,\n",
       " 0.46130162477493286,\n",
       " -0.012570367194712162,\n",
       " 0.0,\n",
       " 0.36357349157333374,\n",
       " 0.35099169611930847,\n",
       " -0.026476139202713966,\n",
       " 0.0,\n",
       " 0.33764973282814026,\n",
       " 0.5242040157318115,\n",
       " 0.056497398763895035,\n",
       " 0.0,\n",
       " 0.345529705286026,\n",
       " 0.5384349822998047,\n",
       " 0.04583882912993431,\n",
       " 0.0,\n",
       " 0.365351140499115,\n",
       " 0.562812089920044,\n",
       " 0.022072510793805122,\n",
       " 0.0,\n",
       " 0.33071354031562805,\n",
       " 0.49899786710739136,\n",
       " 0.1014198437333107,\n",
       " 0.0,\n",
       " 0.34561994671821594,\n",
       " 0.358074426651001,\n",
       " 0.006631381344050169,\n",
       " 0.0,\n",
       " 0.3505426049232483,\n",
       " 0.3903655409812927,\n",
       " -0.021109633147716522,\n",
       " 0.0,\n",
       " 0.3820565342903137,\n",
       " 0.5661581754684448,\n",
       " 0.01494763046503067,\n",
       " 0.0,\n",
       " 0.35854431986808777,\n",
       " 0.5622423887252808,\n",
       " 0.0444243922829628,\n",
       " 0.0,\n",
       " 0.3106136620044708,\n",
       " 0.44254446029663086,\n",
       " 0.0915457084774971,\n",
       " 0.0,\n",
       " 0.3588921129703522,\n",
       " 0.48924949765205383,\n",
       " 0.004726129118353128,\n",
       " 0.0,\n",
       " 0.3576849400997162,\n",
       " 0.49224260449409485,\n",
       " 0.0036726943217217922,\n",
       " 0.0,\n",
       " 0.35686230659484863,\n",
       " 0.49701982736587524,\n",
       " 0.0031412323005497456,\n",
       " 0.0,\n",
       " 0.3567158877849579,\n",
       " 0.5034788250923157,\n",
       " 0.0050231353379786015,\n",
       " 0.0,\n",
       " 0.3576529324054718,\n",
       " 0.5142481327056885,\n",
       " 0.013123114593327045,\n",
       " 0.0,\n",
       " 0.3493049144744873,\n",
       " 0.48831993341445923,\n",
       " 0.015705598518252373,\n",
       " 0.0,\n",
       " 0.3466237187385559,\n",
       " 0.4872889518737793,\n",
       " 0.016471628099679947,\n",
       " 0.0,\n",
       " 0.34420546889305115,\n",
       " 0.48540908098220825,\n",
       " 0.01688491739332676,\n",
       " 0.0,\n",
       " 0.33590060472488403,\n",
       " 0.47797244787216187,\n",
       " 0.019210994243621826,\n",
       " 0.0,\n",
       " 0.3127601742744446,\n",
       " 0.4473347067832947,\n",
       " 0.04201658442616463,\n",
       " 0.0,\n",
       " 0.35255658626556396,\n",
       " 0.3766433000564575,\n",
       " -0.015223853290081024,\n",
       " 0.0,\n",
       " 0.35139328241348267,\n",
       " 0.35278114676475525,\n",
       " -0.002940935315564275,\n",
       " 0.0,\n",
       " 0.34790346026420593,\n",
       " 0.35442614555358887,\n",
       " 0.0028329389169812202,\n",
       " 0.0,\n",
       " 0.3514368236064911,\n",
       " 0.4868319034576416,\n",
       " 0.016187353059649467,\n",
       " 0.0,\n",
       " 0.3181287348270416,\n",
       " 0.4746890068054199,\n",
       " 0.05920930206775665,\n",
       " 0.0,\n",
       " 0.3551234006881714,\n",
       " 0.35331079363822937,\n",
       " -0.016708431765437126,\n",
       " 0.0,\n",
       " 0.35562995076179504,\n",
       " 0.5267490148544312,\n",
       " 0.019868530333042145,\n",
       " 0.0,\n",
       " 0.3590036928653717,\n",
       " 0.3956524729728699,\n",
       " -0.04038403183221817,\n",
       " 0.0,\n",
       " 0.3539466857910156,\n",
       " 0.3843466341495514,\n",
       " -0.03042730875313282,\n",
       " 0.0,\n",
       " 0.3606402277946472,\n",
       " 0.3814789950847626,\n",
       " -0.03509490191936493,\n",
       " 0.0,\n",
       " 0.3459952175617218,\n",
       " 0.4099287986755371,\n",
       " -0.01663384772837162,\n",
       " 0.0,\n",
       " 0.3797508776187897,\n",
       " 0.5529305338859558,\n",
       " 0.008147391490638256,\n",
       " 0.0,\n",
       " 0.3784942030906677,\n",
       " 0.5359042882919312,\n",
       " 0.005879848729819059,\n",
       " 0.0,\n",
       " 0.3662562966346741,\n",
       " 0.534300684928894,\n",
       " 0.011361137963831425,\n",
       " 0.0,\n",
       " 0.3381750285625458,\n",
       " 0.50343257188797,\n",
       " 0.03263722360134125,\n",
       " 0.0,\n",
       " 0.33687031269073486,\n",
       " 0.44048553705215454,\n",
       " 0.007956370711326599,\n",
       " 0.0,\n",
       " 0.3467564582824707,\n",
       " 0.5164246559143066,\n",
       " 0.02699386514723301,\n",
       " 0.0,\n",
       " 0.3224586248397827,\n",
       " 0.4387085437774658,\n",
       " 0.017776023596525192,\n",
       " 0.0,\n",
       " 0.3317984938621521,\n",
       " 0.45296820998191833,\n",
       " 0.013978165574371815,\n",
       " 0.0,\n",
       " 0.31967490911483765,\n",
       " 0.457592636346817,\n",
       " 0.02966194599866867,\n",
       " 0.0,\n",
       " 0.3645251989364624,\n",
       " 0.550239086151123,\n",
       " 0.015258386731147766,\n",
       " 0.0,\n",
       " 0.343619167804718,\n",
       " 0.41568323969841003,\n",
       " -0.00790708139538765,\n",
       " 0.0,\n",
       " 0.33519071340560913,\n",
       " 0.511893093585968,\n",
       " 0.04419698938727379,\n",
       " 0.0,\n",
       " 0.34459444880485535,\n",
       " 0.5264858603477478,\n",
       " 0.03646457940340042,\n",
       " 0.0,\n",
       " 0.330486923456192,\n",
       " 0.48877689242362976,\n",
       " 0.03466719388961792,\n",
       " 0.0,\n",
       " 0.3123193383216858,\n",
       " 0.45948681235313416,\n",
       " 0.06741747260093689,\n",
       " 0.0,\n",
       " 0.3250570297241211,\n",
       " 0.4890611171722412,\n",
       " 0.04598989337682724,\n",
       " 0.0,\n",
       " 0.31571149826049805,\n",
       " 0.466585248708725,\n",
       " 0.09041965007781982,\n",
       " 0.0,\n",
       " 0.3285832405090332,\n",
       " 0.4684823453426361,\n",
       " 0.02250903844833374,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"coords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class']=='Winning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('class', axis= 1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline # allows you to build a ML pipeline\n",
    "from sklearn.preprocessing import StandardScaler # Normalizes your data\n",
    "\n",
    "# Diferent algorithms for diversifing your model training (?)\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr': make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc': make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf': make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(x_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Happy', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Happy', 'Happy', 'Happy', 'Winning', 'Sad', 'Happy',\n",
       "       'Happy', 'Sad', 'Winning', 'Sad', 'Winning', 'Winning', 'Winning',\n",
       "       'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Sad', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Winning', 'Happy', 'Happy', 'Sad',\n",
       "       'Sad', 'Winning', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Sad', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Winning', 'Winning', 'Happy',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Winning', 'Sad', 'Sad', 'Sad', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Sad', 'Happy', 'Happy', 'Happy', 'Sad', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy'], dtype='<U7')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and serialize modwel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # accuracy metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 1.0\n",
      "rf 1.0\n",
      "gb 1.0\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(x_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Happy', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Happy', 'Happy', 'Happy', 'Winning', 'Sad', 'Happy',\n",
       "       'Happy', 'Sad', 'Winning', 'Sad', 'Winning', 'Winning', 'Winning',\n",
       "       'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Sad', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Winning', 'Happy', 'Happy', 'Sad',\n",
       "       'Sad', 'Winning', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Sad', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Winning', 'Winning', 'Happy',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Winning', 'Sad', 'Sad', 'Sad', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Sad', 'Happy', 'Happy', 'Happy', 'Sad', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181        Sad\n",
       "138      Happy\n",
       "11       Happy\n",
       "21       Happy\n",
       "523    Winning\n",
       "        ...   \n",
       "484    Winning\n",
       "122      Happy\n",
       "477    Winning\n",
       "469    Winning\n",
       "134      Happy\n",
       "Name: class, Length: 162, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl','wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('body_language.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning [0.13 0.19 0.68]\n",
      "Winning [0.15 0.16 0.69]\n",
      "Winning [0.14 0.16 0.7 ]\n",
      "Winning [0.17 0.17 0.66]\n",
      "Winning [0.16 0.17 0.67]\n",
      "Winning [0.12 0.26 0.62]\n",
      "Winning [0.1  0.32 0.58]\n",
      "Winning [0.08 0.39 0.53]\n",
      "Winning [0.04 0.43 0.53]\n",
      "Winning [0.08 0.38 0.54]\n",
      "Winning [0.13 0.32 0.55]\n",
      "Winning [0.03 0.24 0.73]\n",
      "Winning [0.09 0.17 0.74]\n",
      "Winning [0.14 0.12 0.74]\n",
      "Winning [0.28 0.04 0.68]\n",
      "Winning [0.28 0.11 0.61]\n",
      "Winning [0.27 0.14 0.59]\n",
      "Winning [0.02 0.42 0.56]\n",
      "Winning [0.02 0.48 0.5 ]\n",
      "Sad [0.01 0.58 0.41]\n",
      "Sad [0.   0.53 0.47]\n",
      "Winning [0.   0.48 0.52]\n",
      "Sad [0.01 0.53 0.46]\n",
      "Sad [0.02 0.59 0.39]\n",
      "Sad [0.01 0.55 0.44]\n",
      "Winning [0.   0.49 0.51]\n",
      "Sad [0.01 0.53 0.46]\n",
      "Sad [0.01 0.55 0.44]\n",
      "Sad [0.01 0.54 0.45]\n",
      "Sad [0.01 0.54 0.45]\n",
      "Sad [0.03 0.64 0.33]\n",
      "Winning [0.28 0.13 0.59]\n",
      "Winning [0.3 0.1 0.6]\n",
      "Winning [0.22 0.09 0.69]\n",
      "Winning [0.27 0.04 0.69]\n",
      "Winning [0.26 0.06 0.68]\n",
      "Winning [0.27 0.06 0.67]\n",
      "Winning [0.24 0.07 0.69]\n",
      "Winning [0.23 0.08 0.69]\n",
      "Winning [0.21 0.03 0.76]\n",
      "Winning [0.14 0.05 0.81]\n",
      "Winning [0.15 0.06 0.79]\n",
      "Winning [0.15 0.02 0.83]\n",
      "Winning [0.14 0.02 0.84]\n",
      "Winning [0.14 0.02 0.84]\n",
      "Winning [0.18 0.02 0.8 ]\n",
      "Winning [0.2  0.02 0.78]\n",
      "Winning [0.26 0.03 0.71]\n",
      "Winning [0.35 0.06 0.59]\n",
      "Winning [0.19 0.03 0.78]\n",
      "Winning [0.21 0.07 0.72]\n",
      "Winning [0.37 0.04 0.59]\n",
      "Happy [0.47 0.07 0.46]\n",
      "Winning [0.26 0.15 0.59]\n",
      "Winning [0.21 0.1  0.69]\n",
      "Winning [0.22 0.19 0.59]\n",
      "Winning [0.36 0.2  0.44]\n",
      "Winning [0.41 0.17 0.42]\n",
      "Winning [0.41 0.17 0.42]\n",
      "Winning [0.41 0.17 0.42]\n",
      "Winning [0.41 0.17 0.42]\n",
      "Happy [0.42 0.18 0.4 ]\n",
      "Winning [0.43 0.13 0.44]\n",
      "Happy [0.43 0.14 0.43]\n",
      "Winning [0.32 0.1  0.58]\n",
      "Winning [0.33 0.07 0.6 ]\n",
      "Winning [0.33 0.1  0.57]\n",
      "Winning [0.34 0.08 0.58]\n",
      "Winning [0.35 0.1  0.55]\n",
      "Winning [0.33 0.08 0.59]\n",
      "Winning [0.31 0.08 0.61]\n",
      "Winning [0.32 0.09 0.59]\n",
      "Winning [0.26 0.08 0.66]\n",
      "Winning [0.27 0.14 0.59]\n",
      "Winning [0.27 0.14 0.59]\n",
      "Winning [0.25 0.17 0.58]\n",
      "Winning [0.18 0.16 0.66]\n",
      "Winning [0.25 0.16 0.59]\n",
      "Winning [0.24 0.17 0.59]\n",
      "Winning [0.26 0.15 0.59]\n",
      "Winning [0.31 0.13 0.56]\n",
      "Happy [0.48 0.08 0.44]\n",
      "Happy [0.55 0.12 0.33]\n",
      "Happy [0.62 0.08 0.3 ]\n",
      "Happy [0.63 0.08 0.29]\n",
      "Happy [0.45 0.13 0.42]\n",
      "Winning [0.39 0.12 0.49]\n",
      "Winning [0.35 0.08 0.57]\n",
      "Winning [0.27 0.04 0.69]\n",
      "Winning [0.25 0.04 0.71]\n",
      "Winning [0.15 0.06 0.79]\n",
      "Winning [0.11 0.04 0.85]\n",
      "Winning [0.09 0.07 0.84]\n",
      "Winning [0.09 0.12 0.79]\n",
      "Winning [0.07 0.08 0.85]\n",
      "Winning [0.07 0.09 0.84]\n",
      "Winning [0.07 0.06 0.87]\n",
      "Winning [0.04 0.05 0.91]\n",
      "Winning [0.03 0.07 0.9 ]\n",
      "Winning [0.05 0.06 0.89]\n",
      "Winning [0.06 0.06 0.88]\n",
      "Winning [0.09 0.13 0.78]\n",
      "Winning [0.17 0.06 0.77]\n",
      "Winning [0.2  0.05 0.75]\n",
      "Winning [0.19 0.06 0.75]\n",
      "Winning [0.2  0.06 0.74]\n",
      "Winning [0.2  0.07 0.73]\n",
      "Winning [0.21 0.05 0.74]\n",
      "Winning [0.18 0.06 0.76]\n",
      "Winning [0.17 0.07 0.76]\n",
      "Winning [0.19 0.07 0.74]\n",
      "Winning [0.19 0.08 0.73]\n",
      "Winning [0.2  0.07 0.73]\n",
      "Winning [0.22 0.06 0.72]\n",
      "Winning [0.19 0.07 0.74]\n",
      "Winning [0.14 0.14 0.72]\n",
      "Winning [0.1  0.18 0.72]\n",
      "Winning [0.09 0.17 0.74]\n",
      "Winning [0.08 0.19 0.73]\n",
      "Winning [0.07 0.23 0.7 ]\n",
      "Winning [0.08 0.21 0.71]\n",
      "Winning [0.07 0.15 0.78]\n",
      "Winning [0.05 0.12 0.83]\n",
      "Winning [0.04 0.12 0.84]\n",
      "Winning [0.04 0.13 0.83]\n",
      "Winning [0.15 0.19 0.66]\n",
      "Winning [0.26 0.17 0.57]\n",
      "Happy [0.49 0.17 0.34]\n",
      "Happy [0.61 0.06 0.33]\n",
      "Happy [0.64 0.02 0.34]\n",
      "Happy [0.64 0.03 0.33]\n",
      "Happy [0.63 0.03 0.34]\n",
      "Happy [0.64 0.05 0.31]\n",
      "Happy [0.66 0.05 0.29]\n",
      "Happy [0.61 0.07 0.32]\n",
      "Happy [0.56 0.14 0.3 ]\n",
      "Happy [0.56 0.14 0.3 ]\n",
      "Happy [0.61 0.14 0.25]\n",
      "Happy [0.73 0.11 0.16]\n",
      "Happy [0.76 0.07 0.17]\n",
      "Happy [0.79 0.05 0.16]\n",
      "Happy [0.79 0.04 0.17]\n",
      "Happy [0.78 0.04 0.18]\n",
      "Happy [0.82 0.04 0.14]\n",
      "Happy [0.82 0.04 0.14]\n",
      "Happy [0.82 0.05 0.13]\n",
      "Happy [0.81 0.07 0.12]\n",
      "Happy [0.82 0.07 0.11]\n",
      "Happy [0.82 0.07 0.11]\n",
      "Happy [0.82 0.07 0.11]\n",
      "Happy [0.82 0.07 0.11]\n",
      "Happy [0.82 0.07 0.11]\n",
      "Happy [0.83 0.08 0.09]\n",
      "Happy [0.84 0.05 0.11]\n",
      "Happy [0.84 0.06 0.1 ]\n",
      "Happy [0.84 0.05 0.11]\n",
      "Sad [0.17 0.52 0.31]\n",
      "Sad [0.05 0.69 0.26]\n",
      "Sad [0.02 0.81 0.17]\n",
      "Sad [0.01 0.83 0.16]\n",
      "Sad [0.01 0.8  0.19]\n",
      "Sad [0.01 0.83 0.16]\n",
      "Sad [0.01 0.82 0.17]\n",
      "Sad [0.01 0.79 0.2 ]\n",
      "Sad [0.01 0.77 0.22]\n",
      "Sad [0.01 0.74 0.25]\n",
      "Sad [0.01 0.78 0.21]\n",
      "Sad [0.01 0.84 0.15]\n",
      "Happy [0.35 0.3  0.35]\n",
      "Winning [0.01 0.44 0.55]\n",
      "Winning [0.   0.35 0.65]\n",
      "Winning [0.   0.24 0.76]\n",
      "Winning [0.  0.2 0.8]\n",
      "Winning [0.   0.24 0.76]\n",
      "Winning [0.   0.23 0.77]\n",
      "Winning [0.   0.18 0.82]\n",
      "Winning [0.   0.14 0.86]\n",
      "Winning [0.   0.08 0.92]\n",
      "Winning [0.   0.13 0.87]\n",
      "Winning [0.   0.15 0.85]\n",
      "Winning [0.01 0.15 0.84]\n",
      "Winning [0.01 0.11 0.88]\n",
      "Winning [0.02 0.05 0.93]\n",
      "Winning [0.18 0.07 0.75]\n",
      "Winning [0.48 0.03 0.49]\n",
      "Winning [0.47 0.05 0.48]\n",
      "Happy [0.49 0.09 0.42]\n",
      "Happy [0.45 0.12 0.43]\n",
      "Happy [0.47 0.13 0.4 ]\n",
      "Happy [0.46 0.12 0.42]\n",
      "Winning [0.45 0.09 0.46]\n",
      "Happy [0.56 0.09 0.35]\n",
      "Winning [0.27 0.03 0.7 ]\n",
      "Winning [0.36 0.03 0.61]\n",
      "Winning [0.32 0.04 0.64]\n",
      "Winning [0.19 0.03 0.78]\n",
      "Winning [0.09 0.11 0.8 ]\n",
      "Winning [0.03 0.14 0.83]\n",
      "Winning [0.03 0.08 0.89]\n",
      "Winning [0.01 0.05 0.94]\n",
      "Winning [0.01 0.04 0.95]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.03 0.02 0.95]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.   0.04 0.96]\n",
      "Winning [0.   0.08 0.92]\n",
      "Winning [0.   0.07 0.93]\n",
      "Winning [0.   0.06 0.94]\n",
      "Winning [0.   0.05 0.95]\n",
      "Winning [0.   0.05 0.95]\n",
      "Winning [0.   0.08 0.92]\n",
      "Winning [0.03 0.14 0.83]\n",
      "Winning [0.04 0.17 0.79]\n",
      "Winning [0.04 0.14 0.82]\n",
      "Winning [0.06 0.17 0.77]\n",
      "Winning [0.07 0.16 0.77]\n",
      "Winning [0.06 0.2  0.74]\n",
      "Winning [0.06 0.19 0.75]\n",
      "Winning [0.07 0.18 0.75]\n",
      "Winning [0.05 0.16 0.79]\n",
      "Winning [0.05 0.11 0.84]\n",
      "Winning [0.07 0.13 0.8 ]\n",
      "Winning [0.07 0.13 0.8 ]\n",
      "Winning [0.08 0.1  0.82]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.05 0.11 0.84]\n",
      "Winning [0.02 0.1  0.88]\n",
      "Winning [0.02 0.08 0.9 ]\n",
      "Winning [0.03 0.1  0.87]\n",
      "Winning [0.02 0.11 0.87]\n",
      "Winning [0.01 0.11 0.88]\n",
      "Winning [0.01 0.1  0.89]\n",
      "Winning [0.01 0.09 0.9 ]\n",
      "Winning [0.01 0.08 0.91]\n",
      "Winning [0.08 0.11 0.81]\n",
      "Winning [0.05 0.12 0.83]\n",
      "Winning [0.03 0.25 0.72]\n",
      "Winning [0.01 0.3  0.69]\n",
      "Winning [0.   0.27 0.73]\n",
      "Winning [0.   0.27 0.73]\n",
      "Winning [0.   0.27 0.73]\n",
      "Winning [0.01 0.3  0.69]\n",
      "Winning [0.   0.32 0.68]\n",
      "Winning [0.03 0.27 0.7 ]\n",
      "Winning [0.01 0.2  0.79]\n",
      "Winning [0.04 0.18 0.78]\n",
      "Winning [0.05 0.14 0.81]\n",
      "Winning [0.04 0.13 0.83]\n",
      "Winning [0.05 0.11 0.84]\n",
      "Winning [0.03 0.11 0.86]\n",
      "Winning [0.03 0.12 0.85]\n",
      "Winning [0.03 0.12 0.85]\n",
      "Winning [0.02 0.15 0.83]\n",
      "Winning [0.02 0.22 0.76]\n",
      "Winning [0.   0.25 0.75]\n",
      "Winning [0.01 0.28 0.71]\n",
      "Winning [0.   0.28 0.72]\n",
      "Winning [0.   0.29 0.71]\n",
      "Winning [0.01 0.17 0.82]\n",
      "Winning [0.02 0.13 0.85]\n",
      "Winning [0.01 0.1  0.89]\n",
      "Winning [0.01 0.04 0.95]\n",
      "Winning [0.01 0.04 0.95]\n",
      "Winning [0.01 0.04 0.95]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.04 0.95]\n",
      "Winning [0.   0.05 0.95]\n",
      "Winning [0.01 0.05 0.94]\n",
      "Winning [0.01 0.06 0.93]\n",
      "Winning [0.01 0.06 0.93]\n",
      "Winning [0.01 0.07 0.92]\n",
      "Winning [0.01 0.05 0.94]\n",
      "Winning [0.01 0.06 0.93]\n",
      "Winning [0.01 0.06 0.93]\n",
      "Winning [0.01 0.06 0.93]\n",
      "Winning [0.01 0.06 0.93]\n",
      "Winning [0.01 0.07 0.92]\n",
      "Winning [0.01 0.07 0.92]\n",
      "Winning [0.02 0.11 0.87]\n",
      "Winning [0.02 0.15 0.83]\n",
      "Winning [0.01 0.13 0.86]\n",
      "Winning [0.01 0.11 0.88]\n",
      "Winning [0.01 0.1  0.89]\n",
      "Winning [0.02 0.12 0.86]\n",
      "Winning [0.01 0.13 0.86]\n",
      "Winning [0.02 0.12 0.86]\n",
      "Winning [0.02 0.15 0.83]\n",
      "Winning [0.02 0.13 0.85]\n",
      "Winning [0.02 0.12 0.86]\n",
      "Winning [0.02 0.16 0.82]\n",
      "Winning [0.02 0.14 0.84]\n",
      "Winning [0.01 0.1  0.89]\n",
      "Winning [0.01 0.11 0.88]\n",
      "Winning [0.02 0.13 0.85]\n",
      "Winning [0.02 0.16 0.82]\n",
      "Winning [0.02 0.16 0.82]\n",
      "Winning [0.02 0.15 0.83]\n",
      "Winning [0.02 0.14 0.84]\n",
      "Winning [0.02 0.14 0.84]\n",
      "Winning [0.02 0.14 0.84]\n",
      "Winning [0.02 0.13 0.85]\n",
      "Winning [0.03 0.14 0.83]\n",
      "Winning [0.06 0.19 0.75]\n",
      "Winning [0.05 0.36 0.59]\n",
      "Winning [0.11 0.42 0.47]\n",
      "Happy [0.49 0.22 0.29]\n",
      "Happy [0.46 0.22 0.32]\n",
      "Happy [0.48 0.27 0.25]\n",
      "Happy [0.52 0.21 0.27]\n",
      "Happy [0.47 0.25 0.28]\n",
      "Happy [0.53 0.22 0.25]\n",
      "Happy [0.53 0.21 0.26]\n",
      "Happy [0.68 0.12 0.2 ]\n",
      "Happy [0.71 0.12 0.17]\n",
      "Happy [0.73 0.08 0.19]\n",
      "Happy [0.74 0.08 0.18]\n",
      "Happy [0.71 0.12 0.17]\n",
      "Happy [0.7  0.13 0.17]\n",
      "Happy [0.7  0.14 0.16]\n",
      "Happy [0.75 0.09 0.16]\n",
      "Happy [0.79 0.08 0.13]\n",
      "Happy [0.82 0.03 0.15]\n",
      "Happy [0.82 0.02 0.16]\n",
      "Happy [0.86 0.02 0.12]\n",
      "Happy [0.87 0.02 0.11]\n",
      "Happy [0.75 0.03 0.22]\n",
      "Happy [0.71 0.02 0.27]\n",
      "Happy [0.63 0.03 0.34]\n",
      "Happy [0.63 0.01 0.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy [0.64 0.01 0.35]\n",
      "Happy [0.63 0.01 0.36]\n",
      "Happy [0.63 0.02 0.35]\n",
      "Happy [0.66 0.04 0.3 ]\n",
      "Happy [0.56 0.09 0.35]\n",
      "Happy [0.55 0.08 0.37]\n",
      "Happy [0.46 0.17 0.37]\n",
      "Winning [0.38 0.23 0.39]\n",
      "Happy [0.39 0.24 0.37]\n",
      "Winning [0.33 0.27 0.4 ]\n",
      "Winning [0.35 0.29 0.36]\n",
      "Winning [0.33 0.25 0.42]\n",
      "Winning [0.33 0.26 0.41]\n",
      "Winning [0.33 0.25 0.42]\n",
      "Winning [0.33 0.25 0.42]\n",
      "Winning [0.33 0.25 0.42]\n",
      "Winning [0.33 0.23 0.44]\n",
      "Winning [0.35 0.25 0.4 ]\n",
      "Winning [0.31 0.23 0.46]\n",
      "Winning [0.34 0.2  0.46]\n",
      "Winning [0.36 0.21 0.43]\n",
      "Winning [0.34 0.21 0.45]\n",
      "Winning [0.34 0.17 0.49]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.34 0.21 0.45]\n",
      "Winning [0.32 0.22 0.46]\n",
      "Winning [0.32 0.2  0.48]\n",
      "Winning [0.32 0.2  0.48]\n",
      "Winning [0.32 0.22 0.46]\n",
      "Winning [0.32 0.22 0.46]\n",
      "Winning [0.32 0.22 0.46]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.33 0.22 0.45]\n",
      "Winning [0.31 0.24 0.45]\n",
      "Winning [0.3  0.24 0.46]\n",
      "Winning [0.31 0.23 0.46]\n",
      "Winning [0.32 0.25 0.43]\n",
      "Winning [0.32 0.23 0.45]\n",
      "Winning [0.31 0.23 0.46]\n",
      "Winning [0.29 0.22 0.49]\n",
      "Winning [0.28 0.25 0.47]\n",
      "Winning [0.25 0.25 0.5 ]\n",
      "Winning [0.26 0.23 0.51]\n",
      "Winning [0.25 0.25 0.5 ]\n",
      "Winning [0.24 0.25 0.51]\n",
      "Winning [0.22 0.21 0.57]\n",
      "Winning [0.23 0.21 0.56]\n",
      "Winning [0.3  0.23 0.47]\n",
      "Winning [0.34 0.14 0.52]\n",
      "Winning [0.46 0.03 0.51]\n",
      "Winning [0.48 0.01 0.51]\n",
      "Winning [0.45 0.05 0.5 ]\n",
      "Winning [0.47 0.03 0.5 ]\n",
      "Happy [0.49 0.03 0.48]\n",
      "Happy [0.51 0.05 0.44]\n",
      "Winning [0.43 0.05 0.52]\n",
      "Happy [0.52 0.02 0.46]\n",
      "Winning [0.44 0.04 0.52]\n",
      "Winning [0.47 0.01 0.52]\n",
      "Winning [0.4  0.02 0.58]\n",
      "Happy [0.49 0.02 0.49]\n",
      "Happy [0.51 0.01 0.48]\n",
      "Winning [0.34 0.04 0.62]\n",
      "Winning [0.31 0.04 0.65]\n",
      "Winning [0.34 0.05 0.61]\n",
      "Winning [0.33 0.04 0.63]\n",
      "Winning [0.32 0.04 0.64]\n",
      "Winning [0.34 0.08 0.58]\n",
      "Winning [0.24 0.05 0.71]\n",
      "Winning [0.25 0.03 0.72]\n",
      "Winning [0.32 0.04 0.64]\n",
      "Winning [0.28 0.03 0.69]\n",
      "Winning [0.3  0.03 0.67]\n",
      "Winning [0.23 0.03 0.74]\n",
      "Winning [0.32 0.03 0.65]\n",
      "Winning [0.22 0.03 0.75]\n",
      "Winning [0.18 0.03 0.79]\n",
      "Winning [0.2  0.04 0.76]\n",
      "Winning [0.19 0.03 0.78]\n",
      "Winning [0.22 0.04 0.74]\n",
      "Winning [0.25 0.04 0.71]\n",
      "Winning [0.26 0.04 0.7 ]\n",
      "Winning [0.26 0.03 0.71]\n",
      "Winning [0.21 0.05 0.74]\n",
      "Winning [0.22 0.05 0.73]\n",
      "Winning [0.22 0.05 0.73]\n",
      "Winning [0.22 0.05 0.73]\n",
      "Winning [0.32 0.03 0.65]\n",
      "Winning [0.35 0.03 0.62]\n",
      "Winning [0.35 0.03 0.62]\n",
      "Winning [0.42 0.03 0.55]\n",
      "Winning [0.37 0.03 0.6 ]\n",
      "Winning [0.35 0.03 0.62]\n",
      "Winning [0.42 0.03 0.55]\n",
      "Winning [0.35 0.03 0.62]\n",
      "Winning [0.39 0.03 0.58]\n",
      "Winning [0.37 0.03 0.6 ]\n",
      "Winning [0.36 0.03 0.61]\n",
      "Winning [0.4  0.03 0.57]\n",
      "Winning [0.39 0.03 0.58]\n",
      "Winning [0.41 0.03 0.56]\n",
      "Winning [0.39 0.04 0.57]\n",
      "Winning [0.39 0.04 0.57]\n",
      "Winning [0.36 0.03 0.61]\n",
      "Winning [0.32 0.04 0.64]\n",
      "Winning [0.31 0.03 0.66]\n",
      "Winning [0.32 0.04 0.64]\n",
      "Winning [0.25 0.03 0.72]\n",
      "Winning [0.27 0.03 0.7 ]\n",
      "Winning [0.28 0.04 0.68]\n",
      "Winning [0.31 0.04 0.65]\n",
      "Winning [0.29 0.04 0.67]\n",
      "Winning [0.28 0.04 0.68]\n",
      "Winning [0.31 0.04 0.65]\n",
      "Winning [0.3  0.04 0.66]\n",
      "Winning [0.3  0.04 0.66]\n",
      "Winning [0.33 0.05 0.62]\n",
      "Winning [0.33 0.03 0.64]\n",
      "Winning [0.34 0.03 0.63]\n",
      "Winning [0.39 0.03 0.58]\n",
      "Winning [0.35 0.03 0.62]\n",
      "Winning [0.32 0.03 0.65]\n",
      "Winning [0.32 0.03 0.65]\n",
      "Winning [0.34 0.03 0.63]\n",
      "Winning [0.36 0.03 0.61]\n",
      "Winning [0.39 0.03 0.58]\n",
      "Winning [0.37 0.03 0.6 ]\n",
      "Winning [0.42 0.04 0.54]\n",
      "Winning [0.41 0.04 0.55]\n",
      "Winning [0.39 0.04 0.57]\n",
      "Winning [0.43 0.03 0.54]\n",
      "Winning [0.46 0.03 0.51]\n",
      "Winning [0.4  0.03 0.57]\n",
      "Winning [0.44 0.03 0.53]\n",
      "Winning [0.41 0.04 0.55]\n",
      "Winning [0.42 0.04 0.54]\n",
      "Winning [0.39 0.04 0.57]\n",
      "Winning [0.41 0.04 0.55]\n",
      "Winning [0.37 0.04 0.59]\n",
      "Winning [0.36 0.04 0.6 ]\n",
      "Winning [0.42 0.03 0.55]\n",
      "Winning [0.4  0.03 0.57]\n",
      "Winning [0.39 0.03 0.58]\n",
      "Winning [0.42 0.04 0.54]\n",
      "Winning [0.41 0.04 0.55]\n",
      "Winning [0.43 0.04 0.53]\n",
      "Winning [0.4  0.04 0.56]\n",
      "Winning [0.39 0.04 0.57]\n",
      "Winning [0.37 0.04 0.59]\n",
      "Winning [0.34 0.06 0.6 ]\n",
      "Winning [0.26 0.06 0.68]\n",
      "Winning [0.29 0.06 0.65]\n",
      "Winning [0.3  0.06 0.64]\n",
      "Winning [0.27 0.05 0.68]\n",
      "Winning [0.27 0.05 0.68]\n",
      "Winning [0.27 0.03 0.7 ]\n",
      "Winning [0.33 0.03 0.64]\n",
      "Winning [0.32 0.03 0.65]\n",
      "Winning [0.24 0.05 0.71]\n",
      "Winning [0.27 0.05 0.68]\n",
      "Winning [0.23 0.05 0.72]\n",
      "Winning [0.27 0.03 0.7 ]\n",
      "Winning [0.42 0.05 0.53]\n",
      "Happy [0.49 0.04 0.47]\n",
      "Winning [0.48 0.03 0.49]\n",
      "Winning [0.48 0.02 0.5 ]\n",
      "Happy [0.49 0.03 0.48]\n",
      "Happy [0.51 0.03 0.46]\n",
      "Happy [0.73 0.   0.27]\n",
      "Winning [0.46 0.06 0.48]\n",
      "Happy [0.48 0.05 0.47]\n",
      "Happy [0.54 0.06 0.4 ]\n",
      "Happy [0.55 0.06 0.39]\n",
      "Winning [0.46 0.03 0.51]\n",
      "Winning [0.46 0.03 0.51]\n",
      "Winning [0.46 0.04 0.5 ]\n",
      "Winning [0.45 0.03 0.52]\n",
      "Winning [0.44 0.03 0.53]\n",
      "Winning [0.46 0.03 0.51]\n",
      "Winning [0.45 0.04 0.51]\n",
      "Winning [0.45 0.03 0.52]\n",
      "Winning [0.42 0.04 0.54]\n",
      "Happy [0.55 0.04 0.41]\n",
      "Winning [0.41 0.04 0.55]\n",
      "Winning [0.43 0.05 0.52]\n",
      "Happy [0.48 0.05 0.47]\n",
      "Winning [0.38 0.05 0.57]\n",
      "Winning [0.4  0.05 0.55]\n",
      "Happy [0.53 0.06 0.41]\n",
      "Happy [0.55 0.04 0.41]\n",
      "Happy [0.49 0.05 0.46]\n",
      "Happy [0.57 0.03 0.4 ]\n",
      "Happy [0.66 0.04 0.3 ]\n",
      "Happy [0.58 0.04 0.38]\n",
      "Winning [0.45 0.04 0.51]\n",
      "Happy [0.48 0.08 0.44]\n",
      "Happy [0.48 0.06 0.46]\n",
      "Winning [0.37 0.08 0.55]\n",
      "Winning [0.45 0.06 0.49]\n",
      "Winning [0.33 0.06 0.61]\n",
      "Winning [0.29 0.09 0.62]\n",
      "Winning [0.2  0.05 0.75]\n",
      "Winning [0.21 0.05 0.74]\n",
      "Winning [0.18 0.05 0.77]\n",
      "Winning [0.13 0.08 0.79]\n",
      "Winning [0.21 0.1  0.69]\n",
      "Winning [0.24 0.08 0.68]\n",
      "Winning [0.24 0.09 0.67]\n",
      "Winning [0.25 0.09 0.66]\n",
      "Winning [0.25 0.07 0.68]\n",
      "Winning [0.24 0.1  0.66]\n",
      "Winning [0.23 0.11 0.66]\n",
      "Winning [0.05 0.17 0.78]\n",
      "Winning [0.06 0.14 0.8 ]\n",
      "Winning [0.01 0.16 0.83]\n",
      "Winning [0.   0.13 0.87]\n",
      "Winning [0.   0.13 0.87]\n",
      "Winning [0.   0.13 0.87]\n",
      "Winning [0.03 0.14 0.83]\n",
      "Winning [0.05 0.12 0.83]\n",
      "Winning [0.05 0.11 0.84]\n",
      "Winning [0.04 0.13 0.83]\n",
      "Winning [0.07 0.14 0.79]\n",
      "Winning [0.05 0.13 0.82]\n",
      "Winning [0.06 0.12 0.82]\n",
      "Winning [0.06 0.14 0.8 ]\n",
      "Winning [0.04 0.11 0.85]\n",
      "Winning [0.07 0.06 0.87]\n",
      "Winning [0.06 0.05 0.89]\n",
      "Winning [0.05 0.04 0.91]\n",
      "Winning [0.03 0.03 0.94]\n",
      "Winning [0.05 0.04 0.91]\n",
      "Winning [0.06 0.04 0.9 ]\n",
      "Winning [0.03 0.05 0.92]\n",
      "Winning [0.04 0.06 0.9 ]\n",
      "Winning [0.04 0.05 0.91]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.04 0.03 0.93]\n",
      "Winning [0.04 0.03 0.93]\n",
      "Winning [0.03 0.03 0.94]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.   0.99]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.   0.99]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.   0.99]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.02 0.01 0.97]\n",
      "Winning [0.02 0.01 0.97]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.   0.99]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.   0.99]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.02 0.05 0.93]\n",
      "Winning [0.02 0.06 0.92]\n",
      "Winning [0.02 0.09 0.89]\n",
      "Winning [0.03 0.08 0.89]\n",
      "Winning [0.03 0.08 0.89]\n",
      "Winning [0.05 0.08 0.87]\n",
      "Winning [0.05 0.13 0.82]\n",
      "Winning [0.04 0.08 0.88]\n",
      "Winning [0.02 0.05 0.93]\n",
      "Winning [0. 0. 1.]\n",
      "Winning [0. 0. 1.]\n",
      "Winning [0. 0. 1.]\n",
      "Winning [0. 0. 1.]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0. 0. 1.]\n",
      "Winning [0. 0. 1.]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.03 0.97]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.03 0.07 0.9 ]\n",
      "Winning [0.05 0.06 0.89]\n",
      "Winning [0.03 0.08 0.89]\n",
      "Winning [0.   0.03 0.97]\n",
      "Winning [0.   0.03 0.97]\n",
      "Winning [0.03 0.07 0.9 ]\n",
      "Winning [0.04 0.07 0.89]\n",
      "Winning [0.   0.08 0.92]\n",
      "Winning [0.   0.08 0.92]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1,circle_radius=1)\n",
    "                                 )\n",
    "        # Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract face landmarks \n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concatenate rows\n",
    "            row = pose_row + face_row\n",
    "            \n",
    "#             # Append class name\n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "            # Make detections\n",
    "            x = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(x)[0]\n",
    "            body_language_prob = model.predict_proba(x)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coordinates\n",
    "            display_coords = tuple(np.multiply(\n",
    "                                np.array(\n",
    "                                    (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                     results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                                     , [640, 480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image,\n",
    "                         (display_coords[0], display_coords[1]+5),\n",
    "                         (display_coords[0]+ len(body_language_class)*20, display_coords[1]-30),\n",
    "                         (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, display_coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "#             # Export to .CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cv2.imshow('Raw webcam feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
