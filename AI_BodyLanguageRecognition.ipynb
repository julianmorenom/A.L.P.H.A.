{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requirements and first setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.8.6.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\julia\\anaconda3\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: pandas in c:\\users\\julia\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (0.13.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (3.17.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (0.35.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.2)\n",
      "Requirement already satisfied: six in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\julia\\anaconda3\\lib\\site-packages (from mediapipe) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1,circle_radius=1)\n",
    "                                 )\n",
    "        # Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Pose landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        cv2.imshow('Raw webcam Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mediapipe.python.solution_base.SolutionOutputs"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Capture landmarks and create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.face_landmarks.landmark) + len(results.pose_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the landmarks format\n",
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the csv file\n",
    "with open('coords.csv', mode='w', newline='')as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class name you're trainig\n",
    "class_name = \"Happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1,circle_radius=1)\n",
    "                                 )\n",
    "        # Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            row = pose_row + face_row\n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        cv2.imshow('Raw webcam Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.377088725566864,\n",
       " 0.4000910520553589,\n",
       " -0.8494803309440613,\n",
       " 0.9998297691345215,\n",
       " 0.41410237550735474,\n",
       " 0.33231469988822937,\n",
       " -0.8451960682868958,\n",
       " 0.9997959733009338,\n",
       " 0.43560677766799927,\n",
       " 0.33191949129104614,\n",
       " -0.8449777364730835,\n",
       " 0.99967360496521,\n",
       " 0.4579119086265564,\n",
       " 0.33251604437828064,\n",
       " -0.8457099199295044,\n",
       " 0.9997970461845398,\n",
       " 0.36254385113716125,\n",
       " 0.3362950086593628,\n",
       " -0.7862470746040344,\n",
       " 0.9997493028640747,\n",
       " 0.34968218207359314,\n",
       " 0.3382493853569031,\n",
       " -0.786911129951477,\n",
       " 0.9995999336242676,\n",
       " 0.33503133058547974,\n",
       " 0.3405217230319977,\n",
       " -0.7875194549560547,\n",
       " 0.9997124671936035,\n",
       " 0.502251923084259,\n",
       " 0.3675001859664917,\n",
       " -0.6513850092887878,\n",
       " 0.9997104406356812,\n",
       " 0.3372694253921509,\n",
       " 0.3799232840538025,\n",
       " -0.3661612868309021,\n",
       " 0.9993034601211548,\n",
       " 0.42581748962402344,\n",
       " 0.4679778516292572,\n",
       " -0.7631285786628723,\n",
       " 0.9999024271965027,\n",
       " 0.36058521270751953,\n",
       " 0.473202645778656,\n",
       " -0.6838585138320923,\n",
       " 0.9998311400413513,\n",
       " 0.6713072657585144,\n",
       " 0.733101487159729,\n",
       " -0.5217053294181824,\n",
       " 0.9991188049316406,\n",
       " 0.24889032542705536,\n",
       " 0.7474600672721863,\n",
       " -0.06367405503988266,\n",
       " 0.9987872242927551,\n",
       " 0.8020962476730347,\n",
       " 1.027490496635437,\n",
       " -0.48699188232421875,\n",
       " 0.4183289706707001,\n",
       " 0.20740430057048798,\n",
       " 1.066985845565796,\n",
       " 0.2506295442581177,\n",
       " 0.2536592483520508,\n",
       " 0.8385289907455444,\n",
       " 1.4867194890975952,\n",
       " -0.49312329292297363,\n",
       " 0.1797296106815338,\n",
       " 0.13998892903327942,\n",
       " 1.4693446159362793,\n",
       " 0.07660628110170364,\n",
       " 0.1476423144340515,\n",
       " 0.8792412877082825,\n",
       " 1.5953088998794556,\n",
       " -0.5234755277633667,\n",
       " 0.17703354358673096,\n",
       " 0.10075888782739639,\n",
       " 1.5727038383483887,\n",
       " 0.01896084100008011,\n",
       " 0.14958617091178894,\n",
       " 0.8229048848152161,\n",
       " 1.6037604808807373,\n",
       " -0.6034413576126099,\n",
       " 0.21833248436450958,\n",
       " 0.13981394469738007,\n",
       " 1.5915368795394897,\n",
       " -0.07282476127147675,\n",
       " 0.17596237361431122,\n",
       " 0.7991901636123657,\n",
       " 1.5633736848831177,\n",
       " -0.5176814794540405,\n",
       " 0.22168609499931335,\n",
       " 0.16615892946720123,\n",
       " 1.5524417161941528,\n",
       " 0.018137075006961823,\n",
       " 0.17160168290138245,\n",
       " 0.5892689228057861,\n",
       " 1.5379034280776978,\n",
       " -0.2018115073442459,\n",
       " 0.0005751312710344791,\n",
       " 0.31032106280326843,\n",
       " 1.530701756477356,\n",
       " 0.20471787452697754,\n",
       " 0.0005608412902802229,\n",
       " 0.5761967897415161,\n",
       " 2.1763014793395996,\n",
       " -0.12115802615880966,\n",
       " 0.0008316783932968974,\n",
       " 0.3027549982070923,\n",
       " 2.1617367267608643,\n",
       " 0.30047810077667236,\n",
       " 0.001176708028651774,\n",
       " 0.5770574808120728,\n",
       " 2.7449629306793213,\n",
       " 0.6202991604804993,\n",
       " 0.0001384033093927428,\n",
       " 0.30140531063079834,\n",
       " 2.7252964973449707,\n",
       " 0.6890294551849365,\n",
       " 0.00023199936549644917,\n",
       " 0.5929639339447021,\n",
       " 2.8378682136535645,\n",
       " 0.6828615665435791,\n",
       " 9.84002836048603e-05,\n",
       " 0.30760207772254944,\n",
       " 2.8165948390960693,\n",
       " 0.717450737953186,\n",
       " 0.0004157750227022916,\n",
       " 0.5133026242256165,\n",
       " 2.9234416484832764,\n",
       " 0.3385029733181,\n",
       " 0.0001673881633905694,\n",
       " 0.301897794008255,\n",
       " 2.906087636947632,\n",
       " 0.28380146622657776,\n",
       " 0.0004233978979755193,\n",
       " 0.36810949444770813,\n",
       " 0.4806097149848938,\n",
       " -0.016003787517547607,\n",
       " 0.0,\n",
       " 0.3577258586883545,\n",
       " 0.4415118992328644,\n",
       " -0.04302625730633736,\n",
       " 0.0,\n",
       " 0.3654845952987671,\n",
       " 0.45167076587677,\n",
       " -0.019900323823094368,\n",
       " 0.0,\n",
       " 0.3527950942516327,\n",
       " 0.3977629244327545,\n",
       " -0.034507330507040024,\n",
       " 0.0,\n",
       " 0.3562472462654114,\n",
       " 0.4288254380226135,\n",
       " -0.047264061868190765,\n",
       " 0.0,\n",
       " 0.357198566198349,\n",
       " 0.4109709858894348,\n",
       " -0.04597053304314613,\n",
       " 0.0,\n",
       " 0.3622037470340729,\n",
       " 0.36623620986938477,\n",
       " -0.030159184709191322,\n",
       " 0.0,\n",
       " 0.3173014521598816,\n",
       " 0.3634161353111267,\n",
       " 0.02283594012260437,\n",
       " 0.0,\n",
       " 0.3623816967010498,\n",
       " 0.33794713020324707,\n",
       " -0.02908872626721859,\n",
       " 0.0,\n",
       " 0.3608987331390381,\n",
       " 0.3214510381221771,\n",
       " -0.03325899690389633,\n",
       " 0.0,\n",
       " 0.35979098081588745,\n",
       " 0.2531140446662903,\n",
       " -0.033133942633867264,\n",
       " 0.0,\n",
       " 0.3690284490585327,\n",
       " 0.48654988408088684,\n",
       " -0.013976243324577808,\n",
       " 0.0,\n",
       " 0.37049323320388794,\n",
       " 0.49027329683303833,\n",
       " -0.01055131759494543,\n",
       " 0.0,\n",
       " 0.37214869260787964,\n",
       " 0.49105578660964966,\n",
       " -0.0063714440912008286,\n",
       " 0.0,\n",
       " 0.37239617109298706,\n",
       " 0.4906752407550812,\n",
       " -0.004660116508603096,\n",
       " 0.0,\n",
       " 0.37222573161125183,\n",
       " 0.4957438111305237,\n",
       " -0.005496366415172815,\n",
       " 0.0,\n",
       " 0.3725851774215698,\n",
       " 0.5020949840545654,\n",
       " -0.006710882764309645,\n",
       " 0.0,\n",
       " 0.3737502098083496,\n",
       " 0.5091457962989807,\n",
       " -0.004975052550435066,\n",
       " 0.0,\n",
       " 0.3772584795951843,\n",
       " 0.5209827423095703,\n",
       " 0.003727078903466463,\n",
       " 0.0,\n",
       " 0.3600707948207855,\n",
       " 0.4473347067832947,\n",
       " -0.03817782178521156,\n",
       " 0.0,\n",
       " 0.3549072742462158,\n",
       " 0.4451836347579956,\n",
       " -0.02436693385243416,\n",
       " 0.0,\n",
       " 0.2989969253540039,\n",
       " 0.3144354224205017,\n",
       " 0.06441771984100342,\n",
       " 0.0,\n",
       " 0.34020137786865234,\n",
       " 0.37079954147338867,\n",
       " 0.008721713908016682,\n",
       " 0.0,\n",
       " 0.3328102231025696,\n",
       " 0.3726680278778076,\n",
       " 0.011923760175704956,\n",
       " 0.0,\n",
       " 0.3254525363445282,\n",
       " 0.3730584979057312,\n",
       " 0.016507405787706375,\n",
       " 0.0,\n",
       " 0.3159555196762085,\n",
       " 0.36738845705986023,\n",
       " 0.025955110788345337,\n",
       " 0.0,\n",
       " 0.34549784660339355,\n",
       " 0.3672277629375458,\n",
       " 0.006264307536184788,\n",
       " 0.0,\n",
       " 0.3248451352119446,\n",
       " 0.3479226231575012,\n",
       " 0.004657328128814697,\n",
       " 0.0,\n",
       " 0.33286845684051514,\n",
       " 0.34742629528045654,\n",
       " 0.0013220603577792645,\n",
       " 0.0,\n",
       " 0.3180960416793823,\n",
       " 0.34971684217453003,\n",
       " 0.01033096481114626,\n",
       " 0.0,\n",
       " 0.31445926427841187,\n",
       " 0.35292184352874756,\n",
       " 0.015845105051994324,\n",
       " 0.0,\n",
       " 0.3118962347507477,\n",
       " 0.37487927079200745,\n",
       " 0.03242045268416405,\n",
       " 0.0,\n",
       " 0.3530604839324951,\n",
       " 0.5400038957595825,\n",
       " 0.026287885382771492,\n",
       " 0.0,\n",
       " 0.31474390625953674,\n",
       " 0.36137521266937256,\n",
       " 0.025902723893523216,\n",
       " 0.0,\n",
       " 0.3020181357860565,\n",
       " 0.36643609404563904,\n",
       " 0.07699679583311081,\n",
       " 0.0,\n",
       " 0.30566883087158203,\n",
       " 0.3668820261955261,\n",
       " 0.0422278456389904,\n",
       " 0.0,\n",
       " 0.3322151303291321,\n",
       " 0.42435023188591003,\n",
       " 0.008671094663441181,\n",
       " 0.0,\n",
       " 0.35827723145484924,\n",
       " 0.478383332490921,\n",
       " -0.011937389150261879,\n",
       " 0.0,\n",
       " 0.3625740706920624,\n",
       " 0.4897533059120178,\n",
       " -0.006370261777192354,\n",
       " 0.0,\n",
       " 0.35023829340934753,\n",
       " 0.48012658953666687,\n",
       " -0.002811438636854291,\n",
       " 0.0,\n",
       " 0.3465522825717926,\n",
       " 0.483263224363327,\n",
       " 0.006687765475362539,\n",
       " 0.0,\n",
       " 0.3565467894077301,\n",
       " 0.4889279007911682,\n",
       " 9.683264215709642e-05,\n",
       " 0.0,\n",
       " 0.3524835705757141,\n",
       " 0.48880699276924133,\n",
       " 0.008159708231687546,\n",
       " 0.0,\n",
       " 0.34328794479370117,\n",
       " 0.498458594083786,\n",
       " 0.025395141914486885,\n",
       " 0.0,\n",
       " 0.35113322734832764,\n",
       " 0.44114986062049866,\n",
       " -0.04066867381334305,\n",
       " 0.0,\n",
       " 0.34897834062576294,\n",
       " 0.429081529378891,\n",
       " -0.04422885552048683,\n",
       " 0.0,\n",
       " 0.30245688557624817,\n",
       " 0.3415603041648865,\n",
       " 0.019072474911808968,\n",
       " 0.0,\n",
       " 0.34551888704299927,\n",
       " 0.39229345321655273,\n",
       " -0.0017809986602514982,\n",
       " 0.0,\n",
       " 0.3385145664215088,\n",
       " 0.43348097801208496,\n",
       " -0.013991435058414936,\n",
       " 0.0,\n",
       " 0.33916956186294556,\n",
       " 0.4261176586151123,\n",
       " -0.011755488812923431,\n",
       " 0.0,\n",
       " 0.3139250576496124,\n",
       " 0.422078937292099,\n",
       " 0.027184218168258667,\n",
       " 0.0,\n",
       " 0.35036683082580566,\n",
       " 0.41234254837036133,\n",
       " -0.04070301726460457,\n",
       " 0.0,\n",
       " 0.31446167826652527,\n",
       " 0.33101433515548706,\n",
       " -0.004857624880969524,\n",
       " 0.0,\n",
       " 0.30618321895599365,\n",
       " 0.3345377743244171,\n",
       " 0.006375654600560665,\n",
       " 0.0,\n",
       " 0.29941999912261963,\n",
       " 0.29415735602378845,\n",
       " 0.04169538989663124,\n",
       " 0.0,\n",
       " 0.34681040048599243,\n",
       " 0.33767834305763245,\n",
       " -0.021826598793268204,\n",
       " 0.0,\n",
       " 0.34050479531288147,\n",
       " 0.3489534854888916,\n",
       " 0.0020636001136153936,\n",
       " 0.0,\n",
       " 0.3361106514930725,\n",
       " 0.4877552390098572,\n",
       " 0.02849358320236206,\n",
       " 0.0,\n",
       " 0.32515430450439453,\n",
       " 0.47383126616477966,\n",
       " 0.11497942358255386,\n",
       " 0.0,\n",
       " 0.3449195623397827,\n",
       " 0.44025054574012756,\n",
       " -0.011987011879682541,\n",
       " 0.0,\n",
       " 0.3518069088459015,\n",
       " 0.44511717557907104,\n",
       " -0.015314414165914059,\n",
       " 0.0,\n",
       " 0.3437742590904236,\n",
       " 0.48783057928085327,\n",
       " 0.025813614949584007,\n",
       " 0.0,\n",
       " 0.3472643196582794,\n",
       " 0.4874311089515686,\n",
       " 0.021954603493213654,\n",
       " 0.0,\n",
       " 0.30258750915527344,\n",
       " 0.32582947611808777,\n",
       " 0.010742733255028725,\n",
       " 0.0,\n",
       " 0.3402244448661804,\n",
       " 0.43784305453300476,\n",
       " -0.008811001665890217,\n",
       " 0.0,\n",
       " 0.32759132981300354,\n",
       " 0.3312068581581116,\n",
       " -0.014349140226840973,\n",
       " 0.0,\n",
       " 0.32474061846733093,\n",
       " 0.32060229778289795,\n",
       " -0.017126288264989853,\n",
       " 0.0,\n",
       " 0.31756269931793213,\n",
       " 0.26476842164993286,\n",
       " -0.005781199317425489,\n",
       " 0.0,\n",
       " 0.30078190565109253,\n",
       " 0.30923014879226685,\n",
       " 0.02408747561275959,\n",
       " 0.0,\n",
       " 0.32132256031036377,\n",
       " 0.2912153899669647,\n",
       " -0.011919084005057812,\n",
       " 0.0,\n",
       " 0.29945212602615356,\n",
       " 0.33523425459861755,\n",
       " 0.026951681822538376,\n",
       " 0.0,\n",
       " 0.29887646436691284,\n",
       " 0.32542550563812256,\n",
       " 0.04446517676115036,\n",
       " 0.0,\n",
       " 0.36009982228279114,\n",
       " 0.4853372573852539,\n",
       " -0.009964840486645699,\n",
       " 0.0,\n",
       " 0.35355979204177856,\n",
       " 0.4858185052871704,\n",
       " -0.0015905204927548766,\n",
       " 0.0,\n",
       " 0.3494008481502533,\n",
       " 0.4863869249820709,\n",
       " 0.0067540486343204975,\n",
       " 0.0,\n",
       " 0.3474961817264557,\n",
       " 0.4424240291118622,\n",
       " -0.011302565224468708,\n",
       " 0.0,\n",
       " 0.3454829454421997,\n",
       " 0.48773789405822754,\n",
       " 0.023612508550286293,\n",
       " 0.0,\n",
       " 0.34842732548713684,\n",
       " 0.4898654818534851,\n",
       " 0.017006170004606247,\n",
       " 0.0,\n",
       " 0.3483844995498657,\n",
       " 0.4869285225868225,\n",
       " 0.021314332261681557,\n",
       " 0.0,\n",
       " 0.34594395756721497,\n",
       " 0.4382639229297638,\n",
       " -0.02492406778037548,\n",
       " 0.0,\n",
       " 0.35493674874305725,\n",
       " 0.4877883791923523,\n",
       " 0.0093553951010108,\n",
       " 0.0,\n",
       " 0.3594101667404175,\n",
       " 0.48893558979034424,\n",
       " 0.0033636116422712803,\n",
       " 0.0,\n",
       " 0.3652321398258209,\n",
       " 0.49040406942367554,\n",
       " -0.0022637080401182175,\n",
       " 0.0,\n",
       " 0.36736583709716797,\n",
       " 0.5200955867767334,\n",
       " 0.007154288236051798,\n",
       " 0.0,\n",
       " 0.3645530343055725,\n",
       " 0.5078796148300171,\n",
       " -0.0013968492858111858,\n",
       " 0.0,\n",
       " 0.3638244569301605,\n",
       " 0.5006673336029053,\n",
       " -0.0027384995482861996,\n",
       " 0.0,\n",
       " 0.36406585574150085,\n",
       " 0.494442880153656,\n",
       " -0.0013866217341274023,\n",
       " 0.0,\n",
       " 0.36492595076560974,\n",
       " 0.4902271628379822,\n",
       " -0.0006514237611554563,\n",
       " 0.0,\n",
       " 0.35445699095726013,\n",
       " 0.4884082078933716,\n",
       " 0.010346590541303158,\n",
       " 0.0,\n",
       " 0.353222131729126,\n",
       " 0.4898219108581543,\n",
       " 0.009280306287109852,\n",
       " 0.0,\n",
       " 0.3517581820487976,\n",
       " 0.4929848909378052,\n",
       " 0.008920764550566673,\n",
       " 0.0,\n",
       " 0.35087448358535767,\n",
       " 0.4970362186431885,\n",
       " 0.011386804282665253,\n",
       " 0.0,\n",
       " 0.3389189839363098,\n",
       " 0.4694673418998718,\n",
       " 0.00908644124865532,\n",
       " 0.0,\n",
       " 0.3154381811618805,\n",
       " 0.41558441519737244,\n",
       " 0.12106722593307495,\n",
       " 0.0,\n",
       " 0.36269116401672363,\n",
       " 0.4490114152431488,\n",
       " -0.02647249959409237,\n",
       " 0.0,\n",
       " 0.3518727123737335,\n",
       " 0.48794201016426086,\n",
       " 0.01676327735185623,\n",
       " 0.0,\n",
       " 0.3500996232032776,\n",
       " 0.48842430114746094,\n",
       " 0.016265416517853737,\n",
       " 0.0,\n",
       " 0.3551349341869354,\n",
       " 0.45117470622062683,\n",
       " -0.014766408130526543,\n",
       " 0.0,\n",
       " 0.34460899233818054,\n",
       " 0.44491201639175415,\n",
       " -0.003328978084027767,\n",
       " 0.0,\n",
       " 0.35342225432395935,\n",
       " 0.44839775562286377,\n",
       " -0.015394837595522404,\n",
       " 0.0,\n",
       " 0.3393581807613373,\n",
       " 0.39920610189437866,\n",
       " 0.00513292383402586,\n",
       " 0.0,\n",
       " 0.32836365699768066,\n",
       " 0.408092737197876,\n",
       " 0.012418197467923164,\n",
       " 0.0,\n",
       " 0.3396916389465332,\n",
       " 0.430768221616745,\n",
       " -0.0060761007480323315,\n",
       " 0.0,\n",
       " 0.3047567903995514,\n",
       " 0.27727097272872925,\n",
       " 0.017281608656048775,\n",
       " 0.0,\n",
       " 0.30775561928749084,\n",
       " 0.29733210802078247,\n",
       " 0.0057996767573058605,\n",
       " 0.0,\n",
       " 0.31114649772644043,\n",
       " 0.32034820318222046,\n",
       " -0.00357989314943552,\n",
       " 0.0,\n",
       " 0.3498818278312683,\n",
       " 0.5066052675247192,\n",
       " 0.019722413271665573,\n",
       " 0.0,\n",
       " 0.3420536518096924,\n",
       " 0.3218401074409485,\n",
       " -0.02674798294901848,\n",
       " 0.0,\n",
       " 0.3382367789745331,\n",
       " 0.28829601407051086,\n",
       " -0.024803347885608673,\n",
       " 0.0,\n",
       " 0.3352055549621582,\n",
       " 0.25734150409698486,\n",
       " -0.02276124432682991,\n",
       " 0.0,\n",
       " 0.3193356990814209,\n",
       " 0.37136954069137573,\n",
       " 0.021900366991758347,\n",
       " 0.0,\n",
       " 0.3064696788787842,\n",
       " 0.38302990794181824,\n",
       " 0.04097555950284004,\n",
       " 0.0,\n",
       " 0.3483406603336334,\n",
       " 0.36402755975723267,\n",
       " 0.005782953463494778,\n",
       " 0.0,\n",
       " 0.3084033131599426,\n",
       " 0.35476428270339966,\n",
       " 0.025792744010686874,\n",
       " 0.0,\n",
       " 0.3493594825267792,\n",
       " 0.3847973346710205,\n",
       " -0.00771418446674943,\n",
       " 0.0,\n",
       " 0.3407815992832184,\n",
       " 0.43062108755111694,\n",
       " -0.024422701448202133,\n",
       " 0.0,\n",
       " 0.3023390471935272,\n",
       " 0.390634685754776,\n",
       " 0.05497623607516289,\n",
       " 0.0,\n",
       " 0.3096914291381836,\n",
       " 0.39190569519996643,\n",
       " 0.03346361219882965,\n",
       " 0.0,\n",
       " 0.3173486590385437,\n",
       " 0.39654847979545593,\n",
       " 0.02289164438843727,\n",
       " 0.0,\n",
       " 0.3305511772632599,\n",
       " 0.3940521776676178,\n",
       " 0.01390058547258377,\n",
       " 0.0,\n",
       " 0.3402356803417206,\n",
       " 0.3881601393222809,\n",
       " 0.007778932340443134,\n",
       " 0.0,\n",
       " 0.34668850898742676,\n",
       " 0.38225868344306946,\n",
       " 0.0018461061408743262,\n",
       " 0.0,\n",
       " 0.3555542826652527,\n",
       " 0.3696836531162262,\n",
       " -0.023645536974072456,\n",
       " 0.0,\n",
       " 0.30368873476982117,\n",
       " 0.4157336354255676,\n",
       " 0.05652344971895218,\n",
       " 0.0,\n",
       " 0.3036663830280304,\n",
       " 0.3527870178222656,\n",
       " 0.03134734928607941,\n",
       " 0.0,\n",
       " 0.3560429513454437,\n",
       " 0.4468224346637726,\n",
       " -0.03630424663424492,\n",
       " 0.0,\n",
       " 0.34491047263145447,\n",
       " 0.40544039011001587,\n",
       " -0.003506772220134735,\n",
       " 0.0,\n",
       " 0.3074467182159424,\n",
       " 0.3629026710987091,\n",
       " 0.10629350692033768,\n",
       " 0.0,\n",
       " 0.35099080204963684,\n",
       " 0.3761124312877655,\n",
       " -0.0025327331386506557,\n",
       " 0.0,\n",
       " 0.34122344851493835,\n",
       " 0.43050581216812134,\n",
       " 0.00263331551104784,\n",
       " 0.0,\n",
       " 0.31319162249565125,\n",
       " 0.36156803369522095,\n",
       " 0.028476353734731674,\n",
       " 0.0,\n",
       " 0.341709703207016,\n",
       " 0.42167240381240845,\n",
       " -0.02205348014831543,\n",
       " 0.0,\n",
       " 0.3195084035396576,\n",
       " 0.44395413994789124,\n",
       " 0.12053725123405457,\n",
       " 0.0,\n",
       " 0.34779608249664307,\n",
       " 0.3599810302257538,\n",
       " 0.007370066829025745,\n",
       " 0.0,\n",
       " 0.3455657958984375,\n",
       " 0.41596272587776184,\n",
       " -0.03291017934679985,\n",
       " 0.0,\n",
       " 0.32924437522888184,\n",
       " 0.507011353969574,\n",
       " 0.06687851250171661,\n",
       " 0.0,\n",
       " 0.33638691902160645,\n",
       " 0.5186811089515686,\n",
       " 0.08426967263221741,\n",
       " 0.0,\n",
       " 0.30609291791915894,\n",
       " 0.41675010323524475,\n",
       " 0.0897127091884613,\n",
       " 0.0,\n",
       " 0.3220902383327484,\n",
       " 0.4895647168159485,\n",
       " 0.07912351936101913,\n",
       " 0.0,\n",
       " 0.3002128303050995,\n",
       " 0.34396857023239136,\n",
       " 0.06303483247756958,\n",
       " 0.0,\n",
       " 0.3537115156650543,\n",
       " 0.5526743531227112,\n",
       " 0.033948272466659546,\n",
       " 0.0,\n",
       " 0.35923486948013306,\n",
       " 0.4485533833503723,\n",
       " -0.025055477395653725,\n",
       " 0.0,\n",
       " 0.34017837047576904,\n",
       " 0.4141499400138855,\n",
       " 0.0028088202234357595,\n",
       " 0.0,\n",
       " 0.30263835191726685,\n",
       " 0.36839500069618225,\n",
       " 0.053447507321834564,\n",
       " 0.0,\n",
       " 0.3249179720878601,\n",
       " 0.3658846914768219,\n",
       " 0.01593617908656597,\n",
       " 0.0,\n",
       " 0.3319666385650635,\n",
       " 0.3659442663192749,\n",
       " 0.01197886187583208,\n",
       " 0.0,\n",
       " 0.34691306948661804,\n",
       " 0.49212634563446045,\n",
       " 0.019544176757335663,\n",
       " 0.0,\n",
       " 0.30753788352012634,\n",
       " 0.4395797848701477,\n",
       " 0.06238522753119469,\n",
       " 0.0,\n",
       " 0.369235098361969,\n",
       " 0.570769727230072,\n",
       " 0.03410274162888527,\n",
       " 0.0,\n",
       " 0.3509237766265869,\n",
       " 0.5502945780754089,\n",
       " 0.056880705058574677,\n",
       " 0.0,\n",
       " 0.34422898292541504,\n",
       " 0.5368543863296509,\n",
       " 0.06906910240650177,\n",
       " 0.0,\n",
       " 0.3599452078342438,\n",
       " 0.28630492091178894,\n",
       " -0.033629655838012695,\n",
       " 0.0,\n",
       " 0.3854958415031433,\n",
       " 0.5742552876472473,\n",
       " 0.02663484588265419,\n",
       " 0.0,\n",
       " 0.3383362293243408,\n",
       " 0.3643121123313904,\n",
       " 0.009103848598897457,\n",
       " 0.0,\n",
       " 0.34365612268447876,\n",
       " 0.3615621328353882,\n",
       " 0.007886763662099838,\n",
       " 0.0,\n",
       " 0.3466024696826935,\n",
       " 0.3604016900062561,\n",
       " 0.008124551735818386,\n",
       " 0.0,\n",
       " 0.30085623264312744,\n",
       " 0.34945568442344666,\n",
       " 0.04125070199370384,\n",
       " 0.0,\n",
       " 0.3414829671382904,\n",
       " 0.3561025857925415,\n",
       " 0.005666229408234358,\n",
       " 0.0,\n",
       " 0.3350095748901367,\n",
       " 0.35575875639915466,\n",
       " 0.005488711874932051,\n",
       " 0.0,\n",
       " 0.3281821012496948,\n",
       " 0.3562542796134949,\n",
       " 0.008159367367625237,\n",
       " 0.0,\n",
       " 0.3216923177242279,\n",
       " 0.3579118847846985,\n",
       " 0.012696572579443455,\n",
       " 0.0,\n",
       " 0.31797167658805847,\n",
       " 0.35980573296546936,\n",
       " 0.01709696464240551,\n",
       " 0.0,\n",
       " 0.30167442560195923,\n",
       " 0.33589914441108704,\n",
       " 0.08721458911895752,\n",
       " 0.0,\n",
       " 0.3203759789466858,\n",
       " 0.3647913336753845,\n",
       " 0.019869621843099594,\n",
       " 0.0,\n",
       " 0.36687755584716797,\n",
       " 0.4606693983078003,\n",
       " -0.016814682632684708,\n",
       " 0.0,\n",
       " 0.3433516025543213,\n",
       " 0.46297022700309753,\n",
       " 0.0006273767212405801,\n",
       " 0.0,\n",
       " 0.343694806098938,\n",
       " 0.438957542181015,\n",
       " -0.016142217442393303,\n",
       " 0.0,\n",
       " 0.35594984889030457,\n",
       " 0.46130162477493286,\n",
       " -0.012570367194712162,\n",
       " 0.0,\n",
       " 0.36357349157333374,\n",
       " 0.35099169611930847,\n",
       " -0.026476139202713966,\n",
       " 0.0,\n",
       " 0.33764973282814026,\n",
       " 0.5242040157318115,\n",
       " 0.056497398763895035,\n",
       " 0.0,\n",
       " 0.345529705286026,\n",
       " 0.5384349822998047,\n",
       " 0.04583882912993431,\n",
       " 0.0,\n",
       " 0.365351140499115,\n",
       " 0.562812089920044,\n",
       " 0.022072510793805122,\n",
       " 0.0,\n",
       " 0.33071354031562805,\n",
       " 0.49899786710739136,\n",
       " 0.1014198437333107,\n",
       " 0.0,\n",
       " 0.34561994671821594,\n",
       " 0.358074426651001,\n",
       " 0.006631381344050169,\n",
       " 0.0,\n",
       " 0.3505426049232483,\n",
       " 0.3903655409812927,\n",
       " -0.021109633147716522,\n",
       " 0.0,\n",
       " 0.3820565342903137,\n",
       " 0.5661581754684448,\n",
       " 0.01494763046503067,\n",
       " 0.0,\n",
       " 0.35854431986808777,\n",
       " 0.5622423887252808,\n",
       " 0.0444243922829628,\n",
       " 0.0,\n",
       " 0.3106136620044708,\n",
       " 0.44254446029663086,\n",
       " 0.0915457084774971,\n",
       " 0.0,\n",
       " 0.3588921129703522,\n",
       " 0.48924949765205383,\n",
       " 0.004726129118353128,\n",
       " 0.0,\n",
       " 0.3576849400997162,\n",
       " 0.49224260449409485,\n",
       " 0.0036726943217217922,\n",
       " 0.0,\n",
       " 0.35686230659484863,\n",
       " 0.49701982736587524,\n",
       " 0.0031412323005497456,\n",
       " 0.0,\n",
       " 0.3567158877849579,\n",
       " 0.5034788250923157,\n",
       " 0.0050231353379786015,\n",
       " 0.0,\n",
       " 0.3576529324054718,\n",
       " 0.5142481327056885,\n",
       " 0.013123114593327045,\n",
       " 0.0,\n",
       " 0.3493049144744873,\n",
       " 0.48831993341445923,\n",
       " 0.015705598518252373,\n",
       " 0.0,\n",
       " 0.3466237187385559,\n",
       " 0.4872889518737793,\n",
       " 0.016471628099679947,\n",
       " 0.0,\n",
       " 0.34420546889305115,\n",
       " 0.48540908098220825,\n",
       " 0.01688491739332676,\n",
       " 0.0,\n",
       " 0.33590060472488403,\n",
       " 0.47797244787216187,\n",
       " 0.019210994243621826,\n",
       " 0.0,\n",
       " 0.3127601742744446,\n",
       " 0.4473347067832947,\n",
       " 0.04201658442616463,\n",
       " 0.0,\n",
       " 0.35255658626556396,\n",
       " 0.3766433000564575,\n",
       " -0.015223853290081024,\n",
       " 0.0,\n",
       " 0.35139328241348267,\n",
       " 0.35278114676475525,\n",
       " -0.002940935315564275,\n",
       " 0.0,\n",
       " 0.34790346026420593,\n",
       " 0.35442614555358887,\n",
       " 0.0028329389169812202,\n",
       " 0.0,\n",
       " 0.3514368236064911,\n",
       " 0.4868319034576416,\n",
       " 0.016187353059649467,\n",
       " 0.0,\n",
       " 0.3181287348270416,\n",
       " 0.4746890068054199,\n",
       " 0.05920930206775665,\n",
       " 0.0,\n",
       " 0.3551234006881714,\n",
       " 0.35331079363822937,\n",
       " -0.016708431765437126,\n",
       " 0.0,\n",
       " 0.35562995076179504,\n",
       " 0.5267490148544312,\n",
       " 0.019868530333042145,\n",
       " 0.0,\n",
       " 0.3590036928653717,\n",
       " 0.3956524729728699,\n",
       " -0.04038403183221817,\n",
       " 0.0,\n",
       " 0.3539466857910156,\n",
       " 0.3843466341495514,\n",
       " -0.03042730875313282,\n",
       " 0.0,\n",
       " 0.3606402277946472,\n",
       " 0.3814789950847626,\n",
       " -0.03509490191936493,\n",
       " 0.0,\n",
       " 0.3459952175617218,\n",
       " 0.4099287986755371,\n",
       " -0.01663384772837162,\n",
       " 0.0,\n",
       " 0.3797508776187897,\n",
       " 0.5529305338859558,\n",
       " 0.008147391490638256,\n",
       " 0.0,\n",
       " 0.3784942030906677,\n",
       " 0.5359042882919312,\n",
       " 0.005879848729819059,\n",
       " 0.0,\n",
       " 0.3662562966346741,\n",
       " 0.534300684928894,\n",
       " 0.011361137963831425,\n",
       " 0.0,\n",
       " 0.3381750285625458,\n",
       " 0.50343257188797,\n",
       " 0.03263722360134125,\n",
       " 0.0,\n",
       " 0.33687031269073486,\n",
       " 0.44048553705215454,\n",
       " 0.007956370711326599,\n",
       " 0.0,\n",
       " 0.3467564582824707,\n",
       " 0.5164246559143066,\n",
       " 0.02699386514723301,\n",
       " 0.0,\n",
       " 0.3224586248397827,\n",
       " 0.4387085437774658,\n",
       " 0.017776023596525192,\n",
       " 0.0,\n",
       " 0.3317984938621521,\n",
       " 0.45296820998191833,\n",
       " 0.013978165574371815,\n",
       " 0.0,\n",
       " 0.31967490911483765,\n",
       " 0.457592636346817,\n",
       " 0.02966194599866867,\n",
       " 0.0,\n",
       " 0.3645251989364624,\n",
       " 0.550239086151123,\n",
       " 0.015258386731147766,\n",
       " 0.0,\n",
       " 0.343619167804718,\n",
       " 0.41568323969841003,\n",
       " -0.00790708139538765,\n",
       " 0.0,\n",
       " 0.33519071340560913,\n",
       " 0.511893093585968,\n",
       " 0.04419698938727379,\n",
       " 0.0,\n",
       " 0.34459444880485535,\n",
       " 0.5264858603477478,\n",
       " 0.03646457940340042,\n",
       " 0.0,\n",
       " 0.330486923456192,\n",
       " 0.48877689242362976,\n",
       " 0.03466719388961792,\n",
       " 0.0,\n",
       " 0.3123193383216858,\n",
       " 0.45948681235313416,\n",
       " 0.06741747260093689,\n",
       " 0.0,\n",
       " 0.3250570297241211,\n",
       " 0.4890611171722412,\n",
       " 0.04598989337682724,\n",
       " 0.0,\n",
       " 0.31571149826049805,\n",
       " 0.466585248708725,\n",
       " 0.09041965007781982,\n",
       " 0.0,\n",
       " 0.3285832405090332,\n",
       " 0.4684823453426361,\n",
       " 0.02250903844833374,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"coords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.384617</td>\n",
       "      <td>0.322729</td>\n",
       "      <td>-0.863890</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.420957</td>\n",
       "      <td>0.268093</td>\n",
       "      <td>-0.840398</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.440225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460277</td>\n",
       "      <td>0.267971</td>\n",
       "      <td>-0.004765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.263719</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.394939</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>-0.852800</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.426580</td>\n",
       "      <td>0.267077</td>\n",
       "      <td>-0.826600</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>0.446114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461741</td>\n",
       "      <td>0.259187</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467443</td>\n",
       "      <td>0.253382</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.399921</td>\n",
       "      <td>0.320605</td>\n",
       "      <td>-0.799390</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>0.428417</td>\n",
       "      <td>0.266148</td>\n",
       "      <td>-0.775850</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.447719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460707</td>\n",
       "      <td>0.258572</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466254</td>\n",
       "      <td>0.252646</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.405029</td>\n",
       "      <td>0.320234</td>\n",
       "      <td>-0.769828</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.431008</td>\n",
       "      <td>0.265737</td>\n",
       "      <td>-0.749469</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>0.450104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464590</td>\n",
       "      <td>0.258797</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470098</td>\n",
       "      <td>0.251838</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.408529</td>\n",
       "      <td>0.319356</td>\n",
       "      <td>-0.746761</td>\n",
       "      <td>0.999661</td>\n",
       "      <td>0.432949</td>\n",
       "      <td>0.264793</td>\n",
       "      <td>-0.726220</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.451852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469811</td>\n",
       "      <td>0.255654</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475156</td>\n",
       "      <td>0.248541</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  Happy  0.384617  0.322729 -0.863890  0.999683  0.420957  0.268093   \n",
       "1  Happy  0.394939  0.321733 -0.852800  0.999668  0.426580  0.267077   \n",
       "2  Happy  0.399921  0.320605 -0.799390  0.999665  0.428417  0.266148   \n",
       "3  Happy  0.405029  0.320234 -0.769828  0.999663  0.431008  0.265737   \n",
       "4  Happy  0.408529  0.319356 -0.746761  0.999661  0.432949  0.264793   \n",
       "\n",
       "         z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "0 -0.840398  0.999702  0.440225  ... -0.009025   0.0  0.460277  0.267971   \n",
       "1 -0.826600  0.999664  0.446114  ... -0.006157   0.0  0.461741  0.259187   \n",
       "2 -0.775850  0.999638  0.447719  ... -0.006671   0.0  0.460707  0.258572   \n",
       "3 -0.749469  0.999610  0.450104  ... -0.005327   0.0  0.464590  0.258797   \n",
       "4 -0.726220  0.999582  0.451852  ... -0.005108   0.0  0.469811  0.255654   \n",
       "\n",
       "       z500  v500      x501      y501      z501  v501  \n",
       "0 -0.004765   0.0  0.466200  0.263719 -0.005456   0.0  \n",
       "1  0.000391   0.0  0.467443  0.253382  0.000196   0.0  \n",
       "2 -0.000163   0.0  0.466254  0.252646 -0.000295   0.0  \n",
       "3  0.002500   0.0  0.470098  0.251838  0.002589   0.0  \n",
       "4  0.003898   0.0  0.475156  0.248541  0.004069   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.441137</td>\n",
       "      <td>0.666129</td>\n",
       "      <td>-0.791712</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.466263</td>\n",
       "      <td>0.618982</td>\n",
       "      <td>-0.760779</td>\n",
       "      <td>0.999092</td>\n",
       "      <td>0.480207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482003</td>\n",
       "      <td>0.604836</td>\n",
       "      <td>-0.004818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487225</td>\n",
       "      <td>0.599934</td>\n",
       "      <td>-0.005975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.492343</td>\n",
       "      <td>0.666716</td>\n",
       "      <td>-0.794794</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.515076</td>\n",
       "      <td>0.623053</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>0.999092</td>\n",
       "      <td>0.529768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554600</td>\n",
       "      <td>0.630891</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558827</td>\n",
       "      <td>0.626944</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.513182</td>\n",
       "      <td>0.669709</td>\n",
       "      <td>-0.795878</td>\n",
       "      <td>0.999550</td>\n",
       "      <td>0.534919</td>\n",
       "      <td>0.629341</td>\n",
       "      <td>-0.755327</td>\n",
       "      <td>0.999106</td>\n",
       "      <td>0.549350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559135</td>\n",
       "      <td>0.629791</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563381</td>\n",
       "      <td>0.626241</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.521317</td>\n",
       "      <td>0.673007</td>\n",
       "      <td>-0.796527</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.543582</td>\n",
       "      <td>0.633126</td>\n",
       "      <td>-0.754130</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>0.558801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563667</td>\n",
       "      <td>0.629704</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567943</td>\n",
       "      <td>0.626198</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.527825</td>\n",
       "      <td>0.672980</td>\n",
       "      <td>-0.749958</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.547923</td>\n",
       "      <td>0.632879</td>\n",
       "      <td>-0.703969</td>\n",
       "      <td>0.999179</td>\n",
       "      <td>0.562581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566912</td>\n",
       "      <td>0.627673</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571098</td>\n",
       "      <td>0.624237</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.379153</td>\n",
       "      <td>0.671279</td>\n",
       "      <td>-0.824848</td>\n",
       "      <td>0.997462</td>\n",
       "      <td>0.407934</td>\n",
       "      <td>0.611139</td>\n",
       "      <td>-0.818989</td>\n",
       "      <td>0.996456</td>\n",
       "      <td>0.423179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446095</td>\n",
       "      <td>0.595919</td>\n",
       "      <td>-0.013760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450853</td>\n",
       "      <td>0.588689</td>\n",
       "      <td>-0.015072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.325317</td>\n",
       "      <td>0.365976</td>\n",
       "      <td>-0.541835</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.354183</td>\n",
       "      <td>0.289572</td>\n",
       "      <td>-0.479076</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.375206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392981</td>\n",
       "      <td>0.289194</td>\n",
       "      <td>-0.010134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397360</td>\n",
       "      <td>0.282464</td>\n",
       "      <td>-0.010931</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.347556</td>\n",
       "      <td>0.375456</td>\n",
       "      <td>-0.571756</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.373050</td>\n",
       "      <td>0.303261</td>\n",
       "      <td>-0.513698</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.392564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412560</td>\n",
       "      <td>0.315234</td>\n",
       "      <td>-0.010160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416993</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>-0.011048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.348621</td>\n",
       "      <td>0.376574</td>\n",
       "      <td>-0.568086</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.373164</td>\n",
       "      <td>0.308331</td>\n",
       "      <td>-0.514107</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.392834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393335</td>\n",
       "      <td>0.317553</td>\n",
       "      <td>-0.021522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397803</td>\n",
       "      <td>0.311829</td>\n",
       "      <td>-0.023017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Winning</td>\n",
       "      <td>0.298126</td>\n",
       "      <td>0.387612</td>\n",
       "      <td>-0.776476</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.323417</td>\n",
       "      <td>0.318861</td>\n",
       "      <td>-0.782958</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.343214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335353</td>\n",
       "      <td>0.319365</td>\n",
       "      <td>-0.028043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340092</td>\n",
       "      <td>0.312391</td>\n",
       "      <td>-0.029970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class        x1        y1        z1        v1        x2        y2  \\\n",
       "284  Winning  0.441137  0.666129 -0.791712  0.999592  0.466263  0.618982   \n",
       "285  Winning  0.492343  0.666716 -0.794794  0.999560  0.515076  0.623053   \n",
       "286  Winning  0.513182  0.669709 -0.795878  0.999550  0.534919  0.629341   \n",
       "287  Winning  0.521317  0.673007 -0.796527  0.999551  0.543582  0.633126   \n",
       "288  Winning  0.527825  0.672980 -0.749958  0.999557  0.547923  0.632879   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "534  Winning  0.379153  0.671279 -0.824848  0.997462  0.407934  0.611139   \n",
       "535  Winning  0.325317  0.365976 -0.541835  0.999976  0.354183  0.289572   \n",
       "536  Winning  0.347556  0.375456 -0.571756  0.999974  0.373050  0.303261   \n",
       "537  Winning  0.348621  0.376574 -0.568086  0.999973  0.373164  0.308331   \n",
       "538  Winning  0.298126  0.387612 -0.776476  0.999973  0.323417  0.318861   \n",
       "\n",
       "           z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "284 -0.760779  0.999092  0.480207  ... -0.002153   0.0  0.482003  0.604836   \n",
       "285 -0.759815  0.999092  0.529768  ... -0.003057   0.0  0.554600  0.630891   \n",
       "286 -0.755327  0.999106  0.549350  ... -0.002900   0.0  0.559135  0.629791   \n",
       "287 -0.754130  0.999145  0.558801  ... -0.002850   0.0  0.563667  0.629704   \n",
       "288 -0.703969  0.999179  0.562581  ... -0.002847   0.0  0.566912  0.627673   \n",
       "..        ...       ...       ...  ...       ...   ...       ...       ...   \n",
       "534 -0.818989  0.996456  0.423179  ... -0.008366   0.0  0.446095  0.595919   \n",
       "535 -0.479076  0.999968  0.375206  ... -0.016548   0.0  0.392981  0.289194   \n",
       "536 -0.513698  0.999963  0.392564  ... -0.015392   0.0  0.412560  0.315234   \n",
       "537 -0.514107  0.999957  0.392834  ... -0.018798   0.0  0.393335  0.317553   \n",
       "538 -0.782958  0.999959  0.343214  ... -0.020061   0.0  0.335353  0.319365   \n",
       "\n",
       "         z500  v500      x501      y501      z501  v501  \n",
       "284 -0.004818   0.0  0.487225  0.599934 -0.005975   0.0  \n",
       "285  0.004186   0.0  0.558827  0.626944  0.004005   0.0  \n",
       "286  0.004248   0.0  0.563381  0.626241  0.004034   0.0  \n",
       "287  0.004229   0.0  0.567943  0.626198  0.004010   0.0  \n",
       "288  0.004385   0.0  0.571098  0.624237  0.004161   0.0  \n",
       "..        ...   ...       ...       ...       ...   ...  \n",
       "534 -0.013760   0.0  0.450853  0.588689 -0.015072   0.0  \n",
       "535 -0.010134   0.0  0.397360  0.282464 -0.010931   0.0  \n",
       "536 -0.010160   0.0  0.416993  0.309700 -0.011048   0.0  \n",
       "537 -0.021522   0.0  0.397803  0.311829 -0.023017   0.0  \n",
       "538 -0.028043   0.0  0.340092  0.312391 -0.029970   0.0  \n",
       "\n",
       "[255 rows x 2005 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']=='Winning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('class', axis= 1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93       Happy\n",
       "347    Winning\n",
       "351    Winning\n",
       "24       Happy\n",
       "514    Winning\n",
       "        ...   \n",
       "279        Sad\n",
       "372    Winning\n",
       "204        Sad\n",
       "53       Happy\n",
       "294    Winning\n",
       "Name: class, Length: 377, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline # allows you to build a ML pipeline\n",
    "from sklearn.preprocessing import StandardScaler # Normalizes your data\n",
    "\n",
    "# Diferent algorithms for diversifing your model training (?)\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr': make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc': make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf': make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(x_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Happy', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Happy', 'Happy', 'Happy', 'Winning', 'Sad', 'Happy',\n",
       "       'Happy', 'Sad', 'Winning', 'Sad', 'Winning', 'Winning', 'Winning',\n",
       "       'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Sad', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Winning', 'Happy', 'Happy', 'Sad',\n",
       "       'Sad', 'Winning', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Sad', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Winning', 'Winning', 'Happy',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Winning', 'Sad', 'Sad', 'Sad', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Sad', 'Happy', 'Happy', 'Happy', 'Sad', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy'], dtype='<U7')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate and serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # accuracy metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ec7816b598de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfit_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit_models' is not defined"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(x_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Happy', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Happy', 'Happy', 'Happy', 'Winning', 'Sad', 'Happy',\n",
       "       'Happy', 'Sad', 'Winning', 'Sad', 'Winning', 'Winning', 'Winning',\n",
       "       'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Sad', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Happy', 'Winning', 'Sad',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Happy', 'Winning', 'Winning', 'Happy', 'Happy', 'Sad',\n",
       "       'Sad', 'Winning', 'Happy', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy', 'Winning', 'Winning',\n",
       "       'Winning', 'Winning', 'Happy', 'Winning', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Winning', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Sad', 'Winning', 'Sad',\n",
       "       'Happy', 'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Winning', 'Winning', 'Happy',\n",
       "       'Winning', 'Winning', 'Winning', 'Winning', 'Happy', 'Winning',\n",
       "       'Winning', 'Sad', 'Happy', 'Winning', 'Sad', 'Sad', 'Sad', 'Happy',\n",
       "       'Winning', 'Sad', 'Winning', 'Happy', 'Winning', 'Happy', 'Happy',\n",
       "       'Sad', 'Happy', 'Happy', 'Happy', 'Sad', 'Happy', 'Winning',\n",
       "       'Happy', 'Winning', 'Winning', 'Happy'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181        Sad\n",
       "138      Happy\n",
       "11       Happy\n",
       "21       Happy\n",
       "523    Winning\n",
       "        ...   \n",
       "484    Winning\n",
       "122      Happy\n",
       "477    Winning\n",
       "469    Winning\n",
       "134      Happy\n",
       "Name: class, Length: 162, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl','wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-de7faa60e679>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'body_language.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m        \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    " with open('body_language.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning [0.11 0.15 0.74]\n",
      "Winning [0.1  0.13 0.77]\n",
      "Winning [0.12 0.11 0.77]\n",
      "Winning [0.11 0.11 0.78]\n",
      "Winning [0.1  0.02 0.88]\n",
      "Winning [0.11 0.02 0.87]\n",
      "Winning [0.06 0.06 0.88]\n",
      "Winning [0.01 0.1  0.89]\n",
      "Winning [0.01 0.08 0.91]\n",
      "Winning [0.01 0.09 0.9 ]\n",
      "Winning [0.01 0.09 0.9 ]\n",
      "Winning [0.01 0.07 0.92]\n",
      "Winning [0.01 0.07 0.92]\n",
      "Winning [0.01 0.07 0.92]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.   0.03 0.97]\n",
      "Winning [0.   0.03 0.97]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.01 0.99]\n",
      "Winning [0.   0.01 0.99]\n",
      "Winning [0.   0.03 0.97]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.03 0.97]\n",
      "Winning [0.   0.02 0.98]\n",
      "Winning [0.   0.01 0.99]\n",
      "Winning [0. 0. 1.]\n",
      "Winning [0.   0.01 0.99]\n",
      "Winning [0.02 0.01 0.97]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.02 0.05 0.93]\n",
      "Winning [0.01 0.04 0.95]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.13 0.86]\n",
      "Winning [0.04 0.1  0.86]\n",
      "Winning [0.04 0.1  0.86]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.07 0.1  0.83]\n",
      "Winning [0.06 0.1  0.84]\n",
      "Winning [0.04 0.07 0.89]\n",
      "Winning [0.02 0.06 0.92]\n",
      "Winning [0.02 0.07 0.91]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.03 0.08 0.89]\n",
      "Winning [0.02 0.03 0.95]\n",
      "Winning [0.02 0.   0.98]\n",
      "Winning [0.01 0.   0.99]\n",
      "Winning [0.04 0.1  0.86]\n",
      "Winning [0.07 0.09 0.84]\n",
      "Winning [0.07 0.09 0.84]\n",
      "Winning [0.1  0.09 0.81]\n",
      "Winning [0.11 0.1  0.79]\n",
      "Winning [0.1  0.09 0.81]\n",
      "Winning [0.1  0.09 0.81]\n",
      "Winning [0.1  0.09 0.81]\n",
      "Winning [0.1  0.09 0.81]\n",
      "Winning [0.1 0.1 0.8]\n",
      "Winning [0.1  0.11 0.79]\n",
      "Winning [0.15 0.09 0.76]\n",
      "Winning [0.09 0.08 0.83]\n",
      "Winning [0.06 0.1  0.84]\n",
      "Winning [0.08 0.12 0.8 ]\n",
      "Winning [0.08 0.12 0.8 ]\n",
      "Winning [0.07 0.12 0.81]\n",
      "Winning [0.06 0.11 0.83]\n",
      "Winning [0.07 0.12 0.81]\n",
      "Winning [0.06 0.11 0.83]\n",
      "Winning [0.07 0.14 0.79]\n",
      "Winning [0.06 0.1  0.84]\n",
      "Winning [0.06 0.12 0.82]\n",
      "Winning [0.06 0.12 0.82]\n",
      "Winning [0.06 0.11 0.83]\n",
      "Winning [0.06 0.09 0.85]\n",
      "Winning [0.05 0.03 0.92]\n",
      "Winning [0.05 0.04 0.91]\n",
      "Winning [0.05 0.05 0.9 ]\n",
      "Winning [0.03 0.04 0.93]\n",
      "Winning [0.03 0.03 0.94]\n",
      "Winning [0.04 0.02 0.94]\n",
      "Winning [0.04 0.03 0.93]\n",
      "Winning [0.  0.2 0.8]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.  0.2 0.8]\n",
      "Winning [0.  0.2 0.8]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.25 0.75]\n",
      "Winning [0.   0.27 0.73]\n",
      "Winning [0.   0.25 0.75]\n",
      "Winning [0.   0.25 0.75]\n",
      "Winning [0.   0.23 0.77]\n",
      "Winning [0.   0.22 0.78]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.22 0.78]\n",
      "Winning [0.   0.22 0.78]\n",
      "Winning [0.   0.22 0.78]\n",
      "Winning [0.   0.22 0.78]\n",
      "Winning [0.   0.24 0.76]\n",
      "Winning [0.   0.24 0.76]\n",
      "Winning [0.   0.24 0.76]\n",
      "Winning [0.   0.23 0.77]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.21 0.79]\n",
      "Winning [0.   0.19 0.81]\n",
      "Winning [0.   0.18 0.82]\n",
      "Winning [0.   0.15 0.85]\n",
      "Winning [0.  0.1 0.9]\n",
      "Winning [0.   0.13 0.87]\n",
      "Winning [0.   0.18 0.82]\n",
      "Winning [0.   0.19 0.81]\n",
      "Winning [0.   0.14 0.86]\n",
      "Winning [0.   0.14 0.86]\n",
      "Winning [0.   0.13 0.87]\n",
      "Winning [0.   0.11 0.89]\n",
      "Winning [0.   0.12 0.88]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.01 0.98]\n",
      "Winning [0.01 0.   0.99]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.02 0.02 0.96]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.03 0.96]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.01 0.02 0.97]\n",
      "Winning [0.02 0.03 0.95]\n",
      "Winning [0.03 0.04 0.93]\n",
      "Winning [0.03 0.05 0.92]\n",
      "Winning [0.03 0.05 0.92]\n",
      "Winning [0.02 0.08 0.9 ]\n",
      "Winning [0.02 0.07 0.91]\n",
      "Winning [0.01 0.07 0.92]\n",
      "Winning [0.01 0.1  0.89]\n",
      "Winning [0.01 0.11 0.88]\n",
      "Winning [0.   0.14 0.86]\n",
      "Winning [0.   0.13 0.87]\n",
      "Winning [0.   0.09 0.91]\n",
      "Winning [0.  0.1 0.9]\n",
      "Winning [0.  0.1 0.9]\n",
      "Winning [0.01 0.12 0.87]\n",
      "Winning [0.02 0.2  0.78]\n",
      "Winning [0.03 0.21 0.76]\n",
      "Winning [0.07 0.23 0.7 ]\n",
      "Winning [0.14 0.21 0.65]\n",
      "Winning [0.24 0.09 0.67]\n",
      "Winning [0.29 0.06 0.65]\n",
      "Winning [0.29 0.06 0.65]\n",
      "Winning [0.23 0.05 0.72]\n",
      "Winning [0.21 0.04 0.75]\n",
      "Winning [0.21 0.03 0.76]\n",
      "Winning [0.16 0.03 0.81]\n",
      "Winning [0.25 0.06 0.69]\n",
      "Winning [0.16 0.07 0.77]\n",
      "Winning [0.19 0.09 0.72]\n",
      "Winning [0.2 0.1 0.7]\n",
      "Winning [0.19 0.1  0.71]\n",
      "Winning [0.23 0.07 0.7 ]\n",
      "Winning [0.2  0.06 0.74]\n",
      "Winning [0.18 0.03 0.79]\n",
      "Winning [0.19 0.04 0.77]\n",
      "Winning [0.18 0.05 0.77]\n",
      "Winning [0.16 0.04 0.8 ]\n",
      "Winning [0.15 0.05 0.8 ]\n",
      "Winning [0.08 0.05 0.87]\n",
      "Winning [0.1  0.04 0.86]\n",
      "Winning [0.1  0.05 0.85]\n",
      "Winning [0.1  0.06 0.84]\n",
      "Winning [0.11 0.1  0.79]\n",
      "Winning [0.12 0.12 0.76]\n",
      "Winning [0.11 0.11 0.78]\n",
      "Winning [0.12 0.11 0.77]\n",
      "Winning [0.12 0.17 0.71]\n",
      "Winning [0.12 0.09 0.79]\n",
      "Winning [0.09 0.14 0.77]\n",
      "Winning [0.13 0.2  0.67]\n",
      "Winning [0.13 0.19 0.68]\n",
      "Winning [0.14 0.18 0.68]\n",
      "Winning [0.12 0.16 0.72]\n",
      "Winning [0.15 0.18 0.67]\n",
      "Winning [0.15 0.17 0.68]\n",
      "Winning [0.04 0.35 0.61]\n",
      "Winning [0.01 0.26 0.73]\n",
      "Winning [0.01 0.21 0.78]\n",
      "Winning [0.01 0.17 0.82]\n",
      "Winning [0.06 0.15 0.79]\n",
      "Winning [0.08 0.09 0.83]\n",
      "Winning [0.08 0.08 0.84]\n",
      "Winning [0.08 0.11 0.81]\n",
      "Winning [0.07 0.14 0.79]\n",
      "Winning [0.07 0.11 0.82]\n",
      "Winning [0.1 0.1 0.8]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1,circle_radius=1)\n",
    "                                 )\n",
    "        # Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,256,121), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract face landmarks \n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concatenate rows\n",
    "            row = pose_row + face_row\n",
    "            \n",
    "#             # Append class name\n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "            # Make detections\n",
    "            x = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(x)[0]\n",
    "            body_language_prob = model.predict_proba(x)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coordinates\n",
    "            display_coords = tuple(np.multiply(\n",
    "                                np.array(\n",
    "                                    (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                     results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                                     , [640, 480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image,\n",
    "                         (display_coords[0], display_coords[1]+5),\n",
    "                         (display_coords[0]+ len(body_language_class)*20, display_coords[1]-30),\n",
    "                         (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, display_coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "#             # Export to .CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cv2.imshow('Raw webcam feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
